# experiment represented by param file
model: 
  type: sithcon
  layer_params:
    # layer 1
    - in_features: 50
      tau_min: 1
      tau_max: 4000
      buff_max: 6500
      dt: 1
      ntau: 400
      k: 35
      g: 0.0
      channels: 35
      kernel_width: 23
      dilation: 2
    # layer 2
    - in_features: 35
      tau_min: 1
      tau_max: 4000
      buff_max: 6500
      dt: 1
      ntau: 400
      k: 35
      g: 0.0
      channels: 35
      kernel_width: 23
      dilation: 2
    # layer 3
    - in_features: 35
      tau_min: 1
      tau_max: 4000
      buff_max: 6500
      dt: 1
      ntau: 400
      k: 35
      g: 0.0
      channels: 35
      kernel_width: 23
      dilation: 2
  # dropout: 0.2
  batch_norm: False
  act_func: relu
  out_classes: 35
optimizer:
  type: adam
  params:
    lr: 0.003
num_epochs: 40
batch_size: 32
train_data_dir: "data/SpeechCommands/processed/train"
collate: batch   # 'single' or 'batch'
val_data_dir: "data/SpeechCommands/processed/val"

# data needs to look like (X, label) where label is an int in [0, out_classes) 
#   and X is a tensor of size (1, num_features, seq_length)
