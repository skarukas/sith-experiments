model: 
  type: logpolar
  layer_params:
    # layer 1
    - in_channels: 3
      out_channels: 32
      tau_min: 1
      tau_max: 8
      ntau: 8
      k: 50
      kernel_size: 
        - 5
        - 5
      num_angles: 8
      theta_pooling: 2
      localization: gaussian
    # layer 2
    - in_channels: 32
      out_channels: 64
      tau_min: 1
      tau_max: 8
      ntau: 8
      k: 50
      kernel_size: 
        - 5
        - 5
      num_angles: 8
      theta_pooling: 2
      localization: gaussian  
    # layer 3
    - in_channels: 64
      out_channels: 128
      tau_min: 1
      tau_max: 8
      ntau: 8
      k: 50
      kernel_size: 
        - 5
        - 5
      num_angles: 8
      stride: 2
      theta_pooling: 2
      localization: gaussian
    # layer 4
    - in_channels: 128
      out_channels: 256
      tau_min: 1
      tau_max: 8
      ntau: 8
      k: 50
      kernel_size: 
        - 5
        - 5
      num_angles: 8
      stride: 2
      theta_pooling: 2
      localization: gaussian
    # layer 5
    - in_channels: 256
      out_channels: 512
      tau_min: 1
      tau_max: 8
      ntau: 8
      k: 50
      kernel_size: 
        - 5
        - 5
      num_angles: 8
      stride: 2
      theta_pooling: 2
      localization: gaussian
  dropout: 0.2
  batch_norm: False
  act_func: relu
  out_classes: 10
  output: max
optimizer:
  type: adam
  params:
    lr: 0.001
num_epochs: 60
batch_size: 32
train_data_dir: 
  type: CIFAR10
  kwargs:
    root: data
    train: True
    download: True
val_data_dir: 
  type: CIFAR10
  kwargs:
    root: data
    train: False
    download: True
collate: batch
