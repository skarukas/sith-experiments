model: 
  type: logpolar
  layer_params:
    # layer 1
    - in_channels: 3
      out_channels: 16
      tau_min: 1
      tau_max: 20
      ntau: 40
      k: 35
      kernel_size: 
        - 5
        - 5
      stride: 2
      num_angles: 10
      theta_pooling: 2
    # layer 2
    - in_channels: 16
      out_channels: 32
      tau_min: 1
      tau_max: 20
      ntau: 40
      k: 35
      kernel_size: 
        - 5
        - 5
      stride: 2
      num_angles: 10
      theta_pooling: 2
    # layer 3
    - in_channels: 32
      out_channels: 64
      tau_min: 1
      tau_max: 20
      ntau: 40
      k: 35
      kernel_size: 
        - 5
        - 5
      stride: 2
      num_angles: 10
      theta_pooling: 2
    # layer 4
    - in_channels: 64
      out_channels: 32
      tau_min: 1
      tau_max: 20
      ntau: 40
      k: 35
      kernel_size: 
        - 5
        - 5
      stride: 2
      num_angles: 10
      theta_pooling: 2
    # layer 5
    - in_channels: 32
      out_channels: 16
      tau_min: 1
      tau_max: 20
      ntau: 40
      k: 35
      kernel_size: 
        - 5
        - 5
      stride: 2
      num_angles: 10
      theta_pooling: 2
  # dropout: 0.2
  batch_norm: False
  act_func: relu
  out_classes: 10
optimizer:
  type: adam
  params:
    lr: 0.001
num_epochs: 40
batch_size: 32
train_data_dir: 
  type: CIFAR10
  kwargs:
    root: data
    train: True
    download: True
val_data_dir: 
  type: CIFAR10
  kwargs:
    root: data
    train: False
    download: True
collate: batch
