model: 
  type: logpolar
  layer_params:
    # layer 1
    - in_channels: 1
      out_channels: 32
      tau_min: 1
      tau_max: 30
      ntau: 20
      num_angles: 12
      topk: 12
      kernel_size: 7
      lp_version: bilinear
    # layer 2
    - in_channels: 32
      out_channels: 64
      tau_min: 1
      tau_max: 30
      ntau: 20
      num_angles: 12
      topk: 12
      kernel_size: 5
      lp_version: bilinear
    # layer 3
    - in_channels: 32
      out_channels: 64
      tau_min: 1
      tau_max: 30
      ntau: 20
      num_angles: 12
      topk: 12
      kernel_size: 5
      lp_version: bilinear
  dropout: 0.2
  batch_norm: False
  act_func: relu
  out_classes: 10
  output: max
optimizer:
  type: adam
  params:
    lr: 0.001
num_epochs: 40
batch_size: 8
train_data_dir: 
  type: MNIST_R
  kwargs:
    root: "data"
    train: True
val_data_dir: 
  type: MNIST_R
  kwargs:
    root: "data"
    train: False
collate: batch
