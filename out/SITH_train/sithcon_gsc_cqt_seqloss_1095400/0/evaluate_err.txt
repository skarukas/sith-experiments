Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X = torch.tensor(X)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/35 [00:14<?, ?it/s, loss=4.78, acc=0.0531]Evaluation:   3%|2         | 1/35 [00:14<08:21, 14.76s/it, loss=4.78, acc=0.0531]Evaluation:   3%|2         | 1/35 [00:28<08:21, 14.76s/it, loss=4.75, acc=0.0422]Evaluation:   6%|5         | 2/35 [00:28<07:48, 14.21s/it, loss=4.75, acc=0.0422]Evaluation:   6%|5         | 2/35 [00:42<07:48, 14.21s/it, loss=4.78, acc=0.0406]Evaluation:   9%|8         | 3/35 [00:42<07:26, 13.95s/it, loss=4.78, acc=0.0406]Evaluation:   9%|8         | 3/35 [00:56<07:26, 13.95s/it, loss=4.77, acc=0.0406]Evaluation:  11%|#1        | 4/35 [00:56<07:13, 14.00s/it, loss=4.77, acc=0.0406]Evaluation:  11%|#1        | 4/35 [01:09<07:13, 14.00s/it, loss=4.79, acc=0.0437]Evaluation:  14%|#4        | 5/35 [01:09<06:55, 13.87s/it, loss=4.79, acc=0.0437]                                                                                 Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 109, in transform
    assert not torch.tensor(X).isnan().any()
AssertionError
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X = torch.tensor(X)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/35 [00:14<?, ?it/s, loss=4.76, acc=0.0406]Evaluation:   3%|2         | 1/35 [00:14<08:27, 14.94s/it, loss=4.76, acc=0.0406]Evaluation:   3%|2         | 1/35 [00:28<08:27, 14.94s/it, loss=4.74, acc=0.0469]Evaluation:   6%|5         | 2/35 [00:28<07:51, 14.29s/it, loss=4.74, acc=0.0469]Evaluation:   6%|5         | 2/35 [00:42<07:51, 14.29s/it, loss=4.72, acc=0.0438]Evaluation:   9%|8         | 3/35 [00:42<07:32, 14.13s/it, loss=4.72, acc=0.0438]Evaluation:   9%|8         | 3/35 [00:56<07:32, 14.13s/it, loss=4.7, acc=0.0445] Evaluation:  11%|#1        | 4/35 [00:56<07:17, 14.11s/it, loss=4.7, acc=0.0445]Evaluation:  11%|#1        | 4/35 [01:11<07:17, 14.11s/it, loss=4.69, acc=0.0494]Evaluation:  14%|#4        | 5/35 [01:11<07:07, 14.26s/it, loss=4.69, acc=0.0494]Evaluation:  14%|#4        | 5/35 [01:25<07:07, 14.26s/it, loss=4.7, acc=0.049]  Evaluation:  17%|#7        | 6/35 [01:25<06:53, 14.26s/it, loss=4.7, acc=0.049]Evaluation:  17%|#7        | 6/35 [01:40<06:53, 14.26s/it, loss=4.69, acc=0.0504]Evaluation:  20%|##        | 7/35 [01:40<06:44, 14.43s/it, loss=4.69, acc=0.0504]                                                                                 Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 110, in transform
    assert not torch.tensor(X).isnan().any()
AssertionError
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X = torch.tensor(X)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/35 [00:14<?, ?it/s, loss=4.62, acc=0.0625]Evaluation:   3%|2         | 1/35 [00:14<08:18, 14.67s/it, loss=4.62, acc=0.0625]                                                                                 Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 109, in transform
    assert not torch.tensor(X).isnan().any()
AssertionError
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X = torch.tensor(X)
                                                  Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 97, in transform
    X = constant_q(
  File "/geode2/home/u080/skarukas/Carbonate/SITH/util.py", line 181, in constant_q
    X = librosa.cqt(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 185, in cqt
    return vqt(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 1010, in vqt
    fft_basis, n_fft, _ = __cqt_filter_fft(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 1063, in __cqt_filter_fft
    basis, lengths = filters.constant_q(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/filters.py", line 566, in constant_q
    sig = util.normalize(sig, norm=norm)
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/util/utils.py", line 865, in normalize
    if not np.all(np.isfinite(S)):
  File "<__array_function__ internals>", line 2, in all
KeyboardInterrupt
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X = torch.tensor(X)
Exception ignored in: <function NpzFile.__del__ at 0x2b92e6c89550>
Traceback (most recent call last):
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/numpy/lib/npyio.py", line 223, in __del__
    self.close()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/numpy/lib/npyio.py", line 215, in close
    self.zip.close()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/zipfile.py", line 1825, in close
    self._write_end_record()
KeyboardInterrupt: 
                                                  Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 43, in __getitem__
    with WavReader(fname) as reader:
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/audiotsm/io/wav.py", line 30, in __init__
    self._reader = wave.open(filename, 'rb')
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/wave.py", line 509, in open
    return Wave_read(f)
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/wave.py", line 159, in __init__
    f = builtins.open(f, 'rb')
KeyboardInterrupt
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X = torch.tensor(X)
                                                  Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 109, in transform
    assert torch.tensor(X).isfinite().all()
AssertionError
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X = torch.tensor(X)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/35 [00:15<?, ?it/s, loss=4.69, acc=0.0406]Evaluation:   3%|2         | 1/35 [00:15<08:36, 15.20s/it, loss=4.69, acc=0.0406]Evaluation:   3%|2         | 1/35 [00:29<08:36, 15.20s/it, loss=4.69, acc=0.0469]Evaluation:   6%|5         | 2/35 [00:29<07:55, 14.42s/it, loss=4.69, acc=0.0469]Evaluation:   6%|5         | 2/35 [00:43<07:55, 14.42s/it, loss=4.7, acc=0.051]  Evaluation:   9%|8         | 3/35 [00:43<07:35, 14.23s/it, loss=4.7, acc=0.051]Evaluation:   9%|8         | 3/35 [00:56<07:35, 14.23s/it, loss=4.72, acc=0.0484]Evaluation:  11%|#1        | 4/35 [00:56<07:16, 14.09s/it, loss=4.72, acc=0.0484]                                                                                 Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 110, in transform
    assert torch.tensor(X).isfinite().all()
AssertionError
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X = torch.tensor(X)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/35 [00:14<?, ?it/s, loss=4.8, acc=0.05]Evaluation:   3%|2         | 1/35 [00:14<08:21, 14.75s/it, loss=4.8, acc=0.05]Evaluation:   3%|2         | 1/35 [00:28<08:21, 14.75s/it, loss=4.75, acc=0.0469]Evaluation:   6%|5         | 2/35 [00:28<07:52, 14.31s/it, loss=4.75, acc=0.0469]Evaluation:   6%|5         | 2/35 [00:43<07:52, 14.31s/it, loss=4.73, acc=0.049] Evaluation:   9%|8         | 3/35 [00:43<07:38, 14.33s/it, loss=4.73, acc=0.049]Evaluation:   9%|8         | 3/35 [00:56<07:38, 14.33s/it, loss=4.71, acc=0.0445]Evaluation:  11%|#1        | 4/35 [00:56<07:16, 14.07s/it, loss=4.71, acc=0.0445]Evaluation:  11%|#1        | 4/35 [01:10<07:16, 14.07s/it, loss=4.74, acc=0.04]  Evaluation:  14%|#4        | 5/35 [01:10<07:01, 14.06s/it, loss=4.74, acc=0.04]Evaluation:  14%|#4        | 5/35 [01:24<07:01, 14.06s/it, loss=4.74, acc=0.0411]Evaluation:  17%|#7        | 6/35 [01:24<06:48, 14.07s/it, loss=4.74, acc=0.0411]Evaluation:  17%|#7        | 6/35 [01:38<06:48, 14.07s/it, loss=4.75, acc=0.042] Evaluation:  20%|##        | 7/35 [01:38<06:30, 13.94s/it, loss=4.75, acc=0.042]Evaluation:  20%|##        | 7/35 [01:52<06:30, 13.94s/it, loss=4.75, acc=0.0422]Evaluation:  23%|##2       | 8/35 [01:52<06:18, 14.02s/it, loss=4.75, acc=0.0422]Evaluation:  23%|##2       | 8/35 [02:06<06:18, 14.02s/it, loss=4.76, acc=0.0427]Evaluation:  26%|##5       | 9/35 [02:06<06:04, 14.01s/it, loss=4.76, acc=0.0427]Evaluation:  26%|##5       | 9/35 [02:20<06:04, 14.01s/it, loss=4.76, acc=0.0419]Evaluation:  29%|##8       | 10/35 [02:20<05:50, 14.04s/it, loss=4.76, acc=0.0419]Evaluation:  29%|##8       | 10/35 [02:34<05:50, 14.04s/it, loss=4.76, acc=0.0432]Evaluation:  31%|###1      | 11/35 [02:34<05:36, 14.03s/it, loss=4.76, acc=0.0432]                                                                                  Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 28, in evaluate
    assert not torch.tensor(X).isnan().any()
AssertionError
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_norm = torch.tensor(X_norm)
                                                  Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 113, in transform
    print(X[not X.isfinite()])
RuntimeError: Boolean value of Tensor with more than one value is ambiguous
Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 133, in <module>
    model = get_model(config)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/util.py", line 14, in get_model
    model = SITHConClassifier(**model_params, collate=config.get('collate', 'batch'))
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/SITHConClassifier.py", line 31, in __init__
    self.sithcon_layers = nn.ModuleList([TCTCT_Layer(l, Activation, dropout, batch_norm) for l in layer_params])
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/SITHConClassifier.py", line 31, in <listcomp>
    self.sithcon_layers = nn.ModuleList([TCTCT_Layer(l, Activation, dropout, batch_norm) for l in layer_params])
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/sithcon_utils/tctct.py", line 61, in __init__
    self.tctct = _TCTCT_Core(layer_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/sithcon_utils/tctct.py", line 23, in __init__
    self.sith = iSITH(**layer_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/sithcon_utils/isith.py", line 72, in __init__
    self.filters = self.filters.type(ttype)
KeyboardInterrupt
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_norm = torch.tensor(X_norm)
                                                  Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 97, in transform
    X = constant_q(
  File "/geode2/home/u080/skarukas/Carbonate/SITH/util.py", line 180, in constant_q
    X = librosa.cqt(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 185, in cqt
    return vqt(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 1010, in vqt
    fft_basis, n_fft, _ = __cqt_filter_fft(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 1090, in __cqt_filter_fft
    fft_basis = util.sparsify_rows(fft_basis, quantile=sparsity, dtype=dtype)
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/util/utils.py", line 1307, in sparsify_rows
    x_sparse[i, idx] = x[i, idx]
KeyboardInterrupt
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_norm = torch.tensor(X_norm)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/35 [00:14<?, ?it/s, loss=4.86, acc=0.0469]Evaluation:   3%|2         | 1/35 [00:14<08:13, 14.52s/it, loss=4.86, acc=0.0469]Evaluation:   3%|2         | 1/35 [00:28<08:13, 14.52s/it, loss=4.75, acc=0.0484]Evaluation:   6%|5         | 2/35 [00:28<07:44, 14.06s/it, loss=4.75, acc=0.0484]Evaluation:   6%|5         | 2/35 [00:41<07:44, 14.06s/it, loss=4.73, acc=0.0469]Evaluation:   9%|8         | 3/35 [00:41<07:25, 13.91s/it, loss=4.73, acc=0.0469]Evaluation:   9%|8         | 3/35 [00:55<07:25, 13.91s/it, loss=4.71, acc=0.0484]Evaluation:  11%|#1        | 4/35 [00:55<07:05, 13.71s/it, loss=4.71, acc=0.0484]Evaluation:  11%|#1        | 4/35 [01:08<07:05, 13.71s/it, loss=4.69, acc=0.0481]Evaluation:  14%|#4        | 5/35 [01:08<06:50, 13.67s/it, loss=4.69, acc=0.0481]                                                                                 Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 115, in transform
    print(X[not X.isfinite()])
RuntimeError: Boolean value of Tensor with more than one value is ambiguous
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_norm = torch.tensor(X_norm)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/35 [00:13<?, ?it/s, loss=4.54, acc=0.0781]Evaluation:   3%|2         | 1/35 [00:13<07:46, 13.71s/it, loss=4.54, acc=0.0781]Evaluation:   3%|2         | 1/35 [00:26<07:46, 13.71s/it, loss=4.59, acc=0.0625]Evaluation:   6%|5         | 2/35 [00:26<07:14, 13.17s/it, loss=4.59, acc=0.0625]Evaluation:   6%|5         | 2/35 [00:39<07:14, 13.17s/it, loss=4.65, acc=0.0615]Evaluation:   9%|8         | 3/35 [00:39<06:54, 12.95s/it, loss=4.65, acc=0.0615]Evaluation:   9%|8         | 3/35 [00:52<06:54, 12.95s/it, loss=4.69, acc=0.0586]Evaluation:  11%|#1        | 4/35 [00:52<06:39, 12.90s/it, loss=4.69, acc=0.0586]Evaluation:  11%|#1        | 4/35 [01:04<06:39, 12.90s/it, loss=4.7, acc=0.0563] Evaluation:  14%|#4        | 5/35 [01:04<06:23, 12.79s/it, loss=4.7, acc=0.0563]Evaluation:  14%|#4        | 5/35 [01:17<06:23, 12.79s/it, loss=4.68, acc=0.0578]Evaluation:  17%|#7        | 6/35 [01:17<06:09, 12.73s/it, loss=4.68, acc=0.0578]Evaluation:  17%|#7        | 6/35 [01:29<06:09, 12.73s/it, loss=4.71, acc=0.0545]Evaluation:  20%|##        | 7/35 [01:29<05:55, 12.68s/it, loss=4.71, acc=0.0545]Evaluation:  20%|##        | 7/35 [01:48<05:55, 12.68s/it, loss=4.72, acc=0.0523]Evaluation:  23%|##2       | 8/35 [01:48<06:33, 14.59s/it, loss=4.72, acc=0.0523]Evaluation:  23%|##2       | 8/35 [02:01<06:33, 14.59s/it, loss=4.71, acc=0.0528]Evaluation:  26%|##5       | 9/35 [02:01<06:04, 14.02s/it, loss=4.71, acc=0.0528]Evaluation:  26%|##5       | 9/35 [02:14<06:04, 14.02s/it, loss=4.71, acc=0.0525]Evaluation:  29%|##8       | 10/35 [02:14<05:42, 13.69s/it, loss=4.71, acc=0.0525]Evaluation:  29%|##8       | 10/35 [02:26<05:42, 13.69s/it, loss=4.71, acc=0.0517]Evaluation:  31%|###1      | 11/35 [02:26<05:19, 13.31s/it, loss=4.71, acc=0.0517]Evaluation:  31%|###1      | 11/35 [02:39<05:19, 13.31s/it, loss=4.69, acc=0.0526]Evaluation:  34%|###4      | 12/35 [02:39<05:00, 13.07s/it, loss=4.69, acc=0.0526]Evaluation:  34%|###4      | 12/35 [02:51<05:00, 13.07s/it, loss=4.69, acc=0.0514]Evaluation:  37%|###7      | 13/35 [02:51<04:40, 12.76s/it, loss=4.69, acc=0.0514]Evaluation:  37%|###7      | 13/35 [03:03<04:40, 12.76s/it, loss=4.7, acc=0.0502] Evaluation:  40%|####      | 14/35 [03:03<04:26, 12.69s/it, loss=4.7, acc=0.0502]Evaluation:  40%|####      | 14/35 [03:16<04:26, 12.69s/it, loss=4.71, acc=0.0508]Evaluation:  43%|####2     | 15/35 [03:16<04:12, 12.61s/it, loss=4.71, acc=0.0508]Evaluation:  43%|####2     | 15/35 [03:28<04:12, 12.61s/it, loss=4.71, acc=0.0508]Evaluation:  46%|####5     | 16/35 [03:28<03:57, 12.52s/it, loss=4.71, acc=0.0508]Evaluation:  46%|####5     | 16/35 [03:41<03:57, 12.52s/it, loss=4.73, acc=0.0504]Evaluation:  49%|####8     | 17/35 [03:41<03:46, 12.56s/it, loss=4.73, acc=0.0504]Evaluation:  49%|####8     | 17/35 [03:53<03:46, 12.56s/it, loss=4.73, acc=0.0493]Evaluation:  51%|#####1    | 18/35 [03:53<03:32, 12.51s/it, loss=4.73, acc=0.0493]Evaluation:  51%|#####1    | 18/35 [04:05<03:32, 12.51s/it, loss=4.74, acc=0.0479]Evaluation:  54%|#####4    | 19/35 [04:05<03:19, 12.47s/it, loss=4.74, acc=0.0479]Evaluation:  54%|#####4    | 19/35 [04:17<03:19, 12.47s/it, loss=4.73, acc=0.0488]Evaluation:  57%|#####7    | 20/35 [04:17<03:05, 12.34s/it, loss=4.73, acc=0.0488]Evaluation:  57%|#####7    | 20/35 [04:30<03:05, 12.34s/it, loss=4.72, acc=0.0493]Evaluation:  60%|######    | 21/35 [04:30<02:51, 12.28s/it, loss=4.72, acc=0.0493]Evaluation:  60%|######    | 21/35 [04:42<02:51, 12.28s/it, loss=4.72, acc=0.0494]Evaluation:  63%|######2   | 22/35 [04:42<02:38, 12.19s/it, loss=4.72, acc=0.0494]Evaluation:  63%|######2   | 22/35 [04:54<02:38, 12.19s/it, loss=4.71, acc=0.0496]Evaluation:  66%|######5   | 23/35 [04:54<02:25, 12.16s/it, loss=4.71, acc=0.0496]Evaluation:  66%|######5   | 23/35 [05:06<02:25, 12.16s/it, loss=4.72, acc=0.0493]Evaluation:  69%|######8   | 24/35 [05:06<02:13, 12.15s/it, loss=4.72, acc=0.0493]Evaluation:  69%|######8   | 24/35 [05:18<02:13, 12.15s/it, loss=4.71, acc=0.0505]Evaluation:  71%|#######1  | 25/35 [05:18<02:00, 12.09s/it, loss=4.71, acc=0.0505]Evaluation:  71%|#######1  | 25/35 [05:30<02:00, 12.09s/it, loss=4.71, acc=0.0502]Evaluation:  74%|#######4  | 26/35 [05:30<01:49, 12.14s/it, loss=4.71, acc=0.0502]Evaluation:  74%|#######4  | 26/35 [05:42<01:49, 12.14s/it, loss=4.72, acc=0.0501]Evaluation:  77%|#######7  | 27/35 [05:42<01:36, 12.09s/it, loss=4.72, acc=0.0501]Evaluation:  77%|#######7  | 27/35 [05:54<01:36, 12.09s/it, loss=4.73, acc=0.0496]Evaluation:  80%|########  | 28/35 [05:54<01:24, 12.04s/it, loss=4.73, acc=0.0496]Evaluation:  80%|########  | 28/35 [06:06<01:24, 12.04s/it, loss=4.74, acc=0.0497]Evaluation:  83%|########2 | 29/35 [06:06<01:12, 12.10s/it, loss=4.74, acc=0.0497]Evaluation:  83%|########2 | 29/35 [06:18<01:12, 12.10s/it, loss=4.73, acc=0.0498]Evaluation:  86%|########5 | 30/35 [06:18<01:00, 12.10s/it, loss=4.73, acc=0.0498]Evaluation:  86%|########5 | 30/35 [06:30<01:00, 12.10s/it, loss=4.73, acc=0.05]  Evaluation:  89%|########8 | 31/35 [06:30<00:48, 12.10s/it, loss=4.73, acc=0.05]Evaluation:  89%|########8 | 31/35 [06:42<00:48, 12.10s/it, loss=4.73, acc=0.0492]Evaluation:  91%|#########1| 32/35 [06:42<00:35, 12.00s/it, loss=4.73, acc=0.0492]                                                                                  Traceback (most recent call last):
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/numpy/core/numerictypes.py", line 323, in issubclass_
    return issubclass(arg1, arg2)
TypeError: issubclass() arg 1 must be a class

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 97, in transform
    X = constant_q(
  File "/geode2/home/u080/skarukas/Carbonate/SITH/util.py", line 180, in constant_q
    X = librosa.cqt(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 185, in cqt
    return vqt(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 956, in vqt
    fft_basis, n_fft, _ = __cqt_filter_fft(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 1063, in __cqt_filter_fft
    basis, lengths = filters.constant_q(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/filters.py", line 566, in constant_q
    sig = util.normalize(sig, norm=norm)
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/util/utils.py", line 855, in normalize
    threshold = tiny(S)
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/util/utils.py", line 1704, in tiny
    if np.issubdtype(x.dtype, np.floating) or np.issubdtype(
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/numpy/core/numerictypes.py", line 387, in issubdtype
    if not issubclass_(arg1, generic):
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/numpy/core/numerictypes.py", line 323, in issubclass_
    return issubclass(arg1, arg2)
KeyboardInterrupt
Evaluation:   0%|          | 0/35 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_norm = torch.tensor(X_norm)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/35 [00:13<?, ?it/s, loss=4.62, acc=0.0375]Evaluation:   3%|2         | 1/35 [00:13<07:25, 13.09s/it, loss=4.62, acc=0.0375]Evaluation:   3%|2         | 1/35 [00:25<07:25, 13.09s/it, loss=4.65, acc=0.0344]Evaluation:   6%|5         | 2/35 [00:25<06:55, 12.58s/it, loss=4.65, acc=0.0344]Evaluation:   6%|5         | 2/35 [00:37<06:55, 12.58s/it, loss=4.67, acc=0.0365]Evaluation:   9%|8         | 3/35 [00:37<06:34, 12.32s/it, loss=4.67, acc=0.0365]Evaluation:   9%|8         | 3/35 [00:49<06:34, 12.32s/it, loss=4.73, acc=0.0344]Evaluation:  11%|#1        | 4/35 [00:49<06:19, 12.26s/it, loss=4.73, acc=0.0344]Evaluation:  11%|#1        | 4/35 [01:01<06:19, 12.26s/it, loss=4.7, acc=0.04]   Evaluation:  14%|#4        | 5/35 [01:01<06:05, 12.17s/it, loss=4.7, acc=0.04]Evaluation:  14%|#4        | 5/35 [01:13<06:05, 12.17s/it, loss=4.68, acc=0.0438]Evaluation:  17%|#7        | 6/35 [01:13<05:53, 12.18s/it, loss=4.68, acc=0.0438]Evaluation:  17%|#7        | 6/35 [01:25<05:53, 12.18s/it, loss=4.68, acc=0.0464]Evaluation:  20%|##        | 7/35 [01:25<05:39, 12.13s/it, loss=4.68, acc=0.0464]Evaluation:  20%|##        | 7/35 [01:37<05:39, 12.13s/it, loss=4.66, acc=0.048] Evaluation:  23%|##2       | 8/35 [01:37<05:26, 12.10s/it, loss=4.66, acc=0.048]Evaluation:  23%|##2       | 8/35 [01:49<05:26, 12.10s/it, loss=4.67, acc=0.0503]Evaluation:  26%|##5       | 9/35 [01:49<05:14, 12.09s/it, loss=4.67, acc=0.0503]Evaluation:  26%|##5       | 9/35 [02:02<05:14, 12.09s/it, loss=4.68, acc=0.0488]Evaluation:  29%|##8       | 10/35 [02:02<05:03, 12.15s/it, loss=4.68, acc=0.0488]Evaluation:  29%|##8       | 10/35 [02:14<05:03, 12.15s/it, loss=4.68, acc=0.0494]Evaluation:  31%|###1      | 11/35 [02:14<04:50, 12.12s/it, loss=4.68, acc=0.0494]Evaluation:  31%|###1      | 11/35 [02:26<04:50, 12.12s/it, loss=4.68, acc=0.0479]Evaluation:  34%|###4      | 12/35 [02:26<04:38, 12.09s/it, loss=4.68, acc=0.0479]Evaluation:  34%|###4      | 12/35 [02:38<04:38, 12.09s/it, loss=4.7, acc=0.0466] Evaluation:  37%|###7      | 13/35 [02:38<04:25, 12.05s/it, loss=4.7, acc=0.0466]Evaluation:  37%|###7      | 13/35 [02:50<04:25, 12.05s/it, loss=4.7, acc=0.0458]Evaluation:  40%|####      | 14/35 [02:50<04:12, 12.03s/it, loss=4.7, acc=0.0458]Evaluation:  40%|####      | 14/35 [03:02<04:12, 12.03s/it, loss=4.7, acc=0.0469]Evaluation:  43%|####2     | 15/35 [03:02<04:00, 12.04s/it, loss=4.7, acc=0.0469]Evaluation:  43%|####2     | 15/35 [03:14<04:00, 12.04s/it, loss=4.71, acc=0.0475]Evaluation:  46%|####5     | 16/35 [03:14<03:48, 12.01s/it, loss=4.71, acc=0.0475]Evaluation:  46%|####5     | 16/35 [03:26<03:48, 12.01s/it, loss=4.7, acc=0.0474] Evaluation:  49%|####8     | 17/35 [03:26<03:35, 11.99s/it, loss=4.7, acc=0.0474]Evaluation:  49%|####8     | 17/35 [03:38<03:35, 11.99s/it, loss=4.7, acc=0.0483]Evaluation:  51%|#####1    | 18/35 [03:38<03:24, 12.02s/it, loss=4.7, acc=0.0483]Evaluation:  51%|#####1    | 18/35 [03:50<03:24, 12.02s/it, loss=4.7, acc=0.0493]Evaluation:  54%|#####4    | 19/35 [03:50<03:11, 11.98s/it, loss=4.7, acc=0.0493]Evaluation:  54%|#####4    | 19/35 [04:01<03:11, 11.98s/it, loss=4.71, acc=0.0492]Evaluation:  57%|#####7    | 20/35 [04:01<02:59, 11.95s/it, loss=4.71, acc=0.0492]Evaluation:  57%|#####7    | 20/35 [04:14<02:59, 11.95s/it, loss=4.71, acc=0.049] Evaluation:  60%|######    | 21/35 [04:14<02:47, 12.00s/it, loss=4.71, acc=0.049]Evaluation:  60%|######    | 21/35 [04:26<02:47, 12.00s/it, loss=4.72, acc=0.0482]Evaluation:  63%|######2   | 22/35 [04:26<02:35, 11.99s/it, loss=4.72, acc=0.0482]Evaluation:  63%|######2   | 22/35 [04:38<02:35, 11.99s/it, loss=4.71, acc=0.0484]Evaluation:  66%|######5   | 23/35 [04:38<02:24, 12.00s/it, loss=4.71, acc=0.0484]Evaluation:  66%|######5   | 23/35 [04:50<02:24, 12.00s/it, loss=4.72, acc=0.048] Evaluation:  69%|######8   | 24/35 [04:50<02:11, 11.99s/it, loss=4.72, acc=0.048]Evaluation:  69%|######8   | 24/35 [05:02<02:11, 11.99s/it, loss=4.72, acc=0.0479]Evaluation:  71%|#######1  | 25/35 [05:02<02:00, 12.02s/it, loss=4.72, acc=0.0479]Evaluation:  71%|#######1  | 25/35 [05:14<02:00, 12.02s/it, loss=4.73, acc=0.0477]Evaluation:  74%|#######4  | 26/35 [05:14<01:48, 12.05s/it, loss=4.73, acc=0.0477]Evaluation:  74%|#######4  | 26/35 [05:26<01:48, 12.05s/it, loss=4.72, acc=0.0477]Evaluation:  77%|#######7  | 27/35 [05:26<01:36, 12.04s/it, loss=4.72, acc=0.0477]Evaluation:  77%|#######7  | 27/35 [05:38<01:36, 12.04s/it, loss=4.72, acc=0.0484]Evaluation:  80%|########  | 28/35 [05:38<01:24, 12.04s/it, loss=4.72, acc=0.0484]Evaluation:  80%|########  | 28/35 [05:50<01:24, 12.04s/it, loss=4.73, acc=0.0484]Evaluation:  83%|########2 | 29/35 [05:50<01:12, 12.03s/it, loss=4.73, acc=0.0484]Evaluation:  83%|########2 | 29/35 [06:02<01:12, 12.03s/it, loss=4.73, acc=0.0484]Evaluation:  86%|########5 | 30/35 [06:02<01:00, 12.03s/it, loss=4.73, acc=0.0484]Evaluation:  86%|########5 | 30/35 [06:14<01:00, 12.03s/it, loss=4.73, acc=0.0494]Evaluation:  89%|########8 | 31/35 [06:14<00:48, 12.01s/it, loss=4.73, acc=0.0494]Evaluation:  89%|########8 | 31/35 [06:26<00:48, 12.01s/it, loss=4.73, acc=0.0494]Evaluation:  91%|#########1| 32/35 [06:26<00:36, 12.01s/it, loss=4.73, acc=0.0494]Evaluation:  91%|#########1| 32/35 [06:38<00:36, 12.01s/it, loss=4.73, acc=0.049] Evaluation:  94%|#########4| 33/35 [06:38<00:23, 11.99s/it, loss=4.73, acc=0.049]Evaluation:  94%|#########4| 33/35 [06:50<00:23, 11.99s/it, loss=4.73, acc=0.0485]Evaluation:  97%|#########7| 34/35 [06:50<00:12, 12.00s/it, loss=4.73, acc=0.0485]Evaluation:  97%|#########7| 34/35 [06:55<00:12, 12.00s/it, loss=4.74, acc=0.0476]Evaluation: 100%|##########| 35/35 [06:55<00:00,  9.84s/it, loss=4.74, acc=0.0476]                                                                                  Evaluation:   0%|          | 0/69 [00:00<?, ?it/s]Evaluation:   0%|          | 0/69 [00:06<?, ?it/s, loss=3.61, acc=0.15]Evaluation:   1%|1         | 1/69 [00:06<07:18,  6.45s/it, loss=3.61, acc=0.15]Evaluation:   1%|1         | 1/69 [00:12<07:18,  6.45s/it, loss=3.66, acc=0.159]Evaluation:   3%|2         | 2/69 [00:12<07:10,  6.43s/it, loss=3.66, acc=0.159]Evaluation:   3%|2         | 2/69 [00:19<07:10,  6.43s/it, loss=3.72, acc=0.135]Evaluation:   4%|4         | 3/69 [00:19<07:04,  6.43s/it, loss=3.72, acc=0.135]Evaluation:   4%|4         | 3/69 [00:25<07:04,  6.43s/it, loss=3.81, acc=0.136]Evaluation:   6%|5         | 4/69 [00:25<06:58,  6.44s/it, loss=3.81, acc=0.136]Evaluation:   6%|5         | 4/69 [00:32<06:58,  6.44s/it, loss=3.79, acc=0.134]Evaluation:   7%|7         | 5/69 [00:32<06:52,  6.45s/it, loss=3.79, acc=0.134]Evaluation:   7%|7         | 5/69 [00:38<06:52,  6.45s/it, loss=3.83, acc=0.133]Evaluation:   9%|8         | 6/69 [00:38<06:45,  6.44s/it, loss=3.83, acc=0.133]Evaluation:   9%|8         | 6/69 [00:45<06:45,  6.44s/it, loss=3.81, acc=0.129]Evaluation:  10%|#         | 7/69 [00:45<06:40,  6.46s/it, loss=3.81, acc=0.129]Evaluation:  10%|#         | 7/69 [00:51<06:40,  6.46s/it, loss=3.82, acc=0.131]Evaluation:  12%|#1        | 8/69 [00:51<06:33,  6.45s/it, loss=3.82, acc=0.131]Evaluation:  12%|#1        | 8/69 [00:58<06:33,  6.45s/it, loss=3.81, acc=0.137]Evaluation:  13%|#3        | 9/69 [00:58<06:26,  6.45s/it, loss=3.81, acc=0.137]Evaluation:  13%|#3        | 9/69 [01:04<06:26,  6.45s/it, loss=3.82, acc=0.132]Evaluation:  14%|#4        | 10/69 [01:04<06:18,  6.42s/it, loss=3.82, acc=0.132]Evaluation:  14%|#4        | 10/69 [01:13<06:18,  6.42s/it, loss=3.83, acc=0.132]Evaluation:  16%|#5        | 11/69 [01:13<06:59,  7.23s/it, loss=3.83, acc=0.132]Evaluation:  16%|#5        | 11/69 [01:22<06:59,  7.23s/it, loss=3.81, acc=0.135]Evaluation:  17%|#7        | 12/69 [01:22<07:20,  7.72s/it, loss=3.81, acc=0.135]Evaluation:  17%|#7        | 12/69 [01:28<07:20,  7.72s/it, loss=3.8, acc=0.132] Evaluation:  19%|#8        | 13/69 [01:28<06:50,  7.33s/it, loss=3.8, acc=0.132]Evaluation:  19%|#8        | 13/69 [01:37<06:50,  7.33s/it, loss=3.81, acc=0.13]Evaluation:  20%|##        | 14/69 [01:37<07:01,  7.66s/it, loss=3.81, acc=0.13]Evaluation:  20%|##        | 14/69 [01:47<07:01,  7.66s/it, loss=3.82, acc=0.128]Evaluation:  22%|##1       | 15/69 [01:47<07:34,  8.42s/it, loss=3.82, acc=0.128]Evaluation:  22%|##1       | 15/69 [01:53<07:34,  8.42s/it, loss=3.8, acc=0.131] Evaluation:  23%|##3       | 16/69 [01:53<06:55,  7.83s/it, loss=3.8, acc=0.131]Evaluation:  23%|##3       | 16/69 [02:00<06:55,  7.83s/it, loss=3.82, acc=0.129]Evaluation:  25%|##4       | 17/69 [02:00<06:26,  7.44s/it, loss=3.82, acc=0.129]Evaluation:  25%|##4       | 17/69 [02:13<06:26,  7.44s/it, loss=3.85, acc=0.126]Evaluation:  26%|##6       | 18/69 [02:13<07:42,  9.06s/it, loss=3.85, acc=0.126]Evaluation:  26%|##6       | 18/69 [02:19<07:42,  9.06s/it, loss=3.84, acc=0.126]Evaluation:  28%|##7       | 19/69 [02:19<06:53,  8.28s/it, loss=3.84, acc=0.126]Evaluation:  28%|##7       | 19/69 [02:26<06:53,  8.28s/it, loss=3.84, acc=0.126]Evaluation:  29%|##8       | 20/69 [02:26<06:19,  7.74s/it, loss=3.84, acc=0.126]Evaluation:  29%|##8       | 20/69 [02:38<06:19,  7.74s/it, loss=3.84, acc=0.126]Evaluation:  30%|###       | 21/69 [02:38<07:23,  9.24s/it, loss=3.84, acc=0.126]Evaluation:  30%|###       | 21/69 [02:45<07:23,  9.24s/it, loss=3.83, acc=0.126]Evaluation:  32%|###1      | 22/69 [02:45<06:34,  8.39s/it, loss=3.83, acc=0.126]Evaluation:  32%|###1      | 22/69 [02:51<06:34,  8.39s/it, loss=3.85, acc=0.126]Evaluation:  33%|###3      | 23/69 [02:51<05:59,  7.82s/it, loss=3.85, acc=0.126]Evaluation:  33%|###3      | 23/69 [03:02<05:59,  7.82s/it, loss=3.85, acc=0.126]Evaluation:  35%|###4      | 24/69 [03:02<06:33,  8.75s/it, loss=3.85, acc=0.126]Evaluation:  35%|###4      | 24/69 [03:13<06:33,  8.75s/it, loss=3.85, acc=0.126]Evaluation:  36%|###6      | 25/69 [03:13<06:51,  9.35s/it, loss=3.85, acc=0.126]Evaluation:  36%|###6      | 25/69 [03:24<06:51,  9.35s/it, loss=3.85, acc=0.126]Evaluation:  38%|###7      | 26/69 [03:24<07:00,  9.77s/it, loss=3.85, acc=0.126]Evaluation:  38%|###7      | 26/69 [03:30<07:00,  9.77s/it, loss=3.86, acc=0.125]Evaluation:  39%|###9      | 27/69 [03:30<06:09,  8.80s/it, loss=3.86, acc=0.125]Evaluation:  39%|###9      | 27/69 [03:37<06:09,  8.80s/it, loss=3.85, acc=0.124]Evaluation:  41%|####      | 28/69 [03:37<05:33,  8.13s/it, loss=3.85, acc=0.124]Evaluation:  41%|####      | 28/69 [03:43<05:33,  8.13s/it, loss=3.85, acc=0.123]Evaluation:  42%|####2     | 29/69 [03:43<05:06,  7.66s/it, loss=3.85, acc=0.123]Evaluation:  42%|####2     | 29/69 [03:50<05:06,  7.66s/it, loss=3.85, acc=0.123]Evaluation:  43%|####3     | 30/69 [03:50<04:45,  7.31s/it, loss=3.85, acc=0.123]Evaluation:  43%|####3     | 30/69 [03:56<04:45,  7.31s/it, loss=3.85, acc=0.124]Evaluation:  45%|####4     | 31/69 [03:56<04:29,  7.09s/it, loss=3.85, acc=0.124]Evaluation:  45%|####4     | 31/69 [04:03<04:29,  7.09s/it, loss=3.85, acc=0.123]Evaluation:  46%|####6     | 32/69 [04:03<04:16,  6.92s/it, loss=3.85, acc=0.123]Evaluation:  46%|####6     | 32/69 [04:17<04:16,  6.92s/it, loss=3.85, acc=0.123]Evaluation:  48%|####7     | 33/69 [04:17<05:23,  8.97s/it, loss=3.85, acc=0.123]Evaluation:  48%|####7     | 33/69 [04:23<05:23,  8.97s/it, loss=3.85, acc=0.122]Evaluation:  49%|####9     | 34/69 [04:23<04:48,  8.26s/it, loss=3.85, acc=0.122]Evaluation:  49%|####9     | 34/69 [04:30<04:48,  8.26s/it, loss=3.85, acc=0.122]Evaluation:  51%|#####     | 35/69 [04:30<04:23,  7.75s/it, loss=3.85, acc=0.122]Evaluation:  51%|#####     | 35/69 [04:43<04:23,  7.75s/it, loss=3.85, acc=0.121]Evaluation:  52%|#####2    | 36/69 [04:43<05:07,  9.31s/it, loss=3.85, acc=0.121]Evaluation:  52%|#####2    | 36/69 [04:55<05:07,  9.31s/it, loss=3.85, acc=0.12] Evaluation:  54%|#####3    | 37/69 [04:55<05:26, 10.20s/it, loss=3.85, acc=0.12]Evaluation:  54%|#####3    | 37/69 [05:10<05:26, 10.20s/it, loss=3.85, acc=0.12]Evaluation:  55%|#####5    | 38/69 [05:10<05:57, 11.55s/it, loss=3.85, acc=0.12]Evaluation:  55%|#####5    | 38/69 [05:16<05:57, 11.55s/it, loss=3.86, acc=0.119]Evaluation:  57%|#####6    | 39/69 [05:16<05:02, 10.08s/it, loss=3.86, acc=0.119]Evaluation:  57%|#####6    | 39/69 [05:30<05:02, 10.08s/it, loss=3.86, acc=0.119]Evaluation:  58%|#####7    | 40/69 [05:30<05:21, 11.08s/it, loss=3.86, acc=0.119]Evaluation:  58%|#####7    | 40/69 [05:40<05:21, 11.08s/it, loss=3.87, acc=0.118]Evaluation:  59%|#####9    | 41/69 [05:40<05:04, 10.89s/it, loss=3.87, acc=0.118]Evaluation:  59%|#####9    | 41/69 [05:50<05:04, 10.89s/it, loss=3.87, acc=0.118]Evaluation:  61%|######    | 42/69 [05:50<04:47, 10.64s/it, loss=3.87, acc=0.118]Evaluation:  61%|######    | 42/69 [05:57<04:47, 10.64s/it, loss=3.87, acc=0.118]Evaluation:  62%|######2   | 43/69 [05:57<04:04,  9.41s/it, loss=3.87, acc=0.118]Evaluation:  62%|######2   | 43/69 [06:03<04:04,  9.41s/it, loss=3.87, acc=0.118]Evaluation:  64%|######3   | 44/69 [06:03<03:33,  8.52s/it, loss=3.87, acc=0.118]Evaluation:  64%|######3   | 44/69 [06:10<03:33,  8.52s/it, loss=3.87, acc=0.118]Evaluation:  65%|######5   | 45/69 [06:10<03:10,  7.92s/it, loss=3.87, acc=0.118]Evaluation:  65%|######5   | 45/69 [06:16<03:10,  7.92s/it, loss=3.86, acc=0.118]Evaluation:  67%|######6   | 46/69 [06:16<02:52,  7.51s/it, loss=3.86, acc=0.118]Evaluation:  67%|######6   | 46/69 [06:23<02:52,  7.51s/it, loss=3.87, acc=0.118]Evaluation:  68%|######8   | 47/69 [06:23<02:38,  7.21s/it, loss=3.87, acc=0.118]Evaluation:  68%|######8   | 47/69 [06:30<02:38,  7.21s/it, loss=3.87, acc=0.118]Evaluation:  70%|######9   | 48/69 [06:30<02:28,  7.08s/it, loss=3.87, acc=0.118]Evaluation:  70%|######9   | 48/69 [06:36<02:28,  7.08s/it, loss=3.87, acc=0.117]Evaluation:  71%|#######1  | 49/69 [06:36<02:18,  6.92s/it, loss=3.87, acc=0.117]Evaluation:  71%|#######1  | 49/69 [06:43<02:18,  6.92s/it, loss=3.87, acc=0.117]Evaluation:  72%|#######2  | 50/69 [06:43<02:09,  6.79s/it, loss=3.87, acc=0.117]Evaluation:  72%|#######2  | 50/69 [06:49<02:09,  6.79s/it, loss=3.87, acc=0.116]Evaluation:  74%|#######3  | 51/69 [06:49<02:00,  6.70s/it, loss=3.87, acc=0.116]Evaluation:  74%|#######3  | 51/69 [06:56<02:00,  6.70s/it, loss=3.87, acc=0.116]Evaluation:  75%|#######5  | 52/69 [06:56<01:53,  6.66s/it, loss=3.87, acc=0.116]Evaluation:  75%|#######5  | 52/69 [07:02<01:53,  6.66s/it, loss=3.87, acc=0.117]Evaluation:  77%|#######6  | 53/69 [07:02<01:46,  6.64s/it, loss=3.87, acc=0.117]Evaluation:  77%|#######6  | 53/69 [07:09<01:46,  6.64s/it, loss=3.87, acc=0.117]Evaluation:  78%|#######8  | 54/69 [07:09<01:39,  6.61s/it, loss=3.87, acc=0.117]Evaluation:  78%|#######8  | 54/69 [07:15<01:39,  6.61s/it, loss=3.87, acc=0.117]Evaluation:  80%|#######9  | 55/69 [07:15<01:32,  6.59s/it, loss=3.87, acc=0.117]Evaluation:  80%|#######9  | 55/69 [07:22<01:32,  6.59s/it, loss=3.87, acc=0.117]Evaluation:  81%|########1 | 56/69 [07:22<01:25,  6.56s/it, loss=3.87, acc=0.117]Evaluation:  81%|########1 | 56/69 [07:28<01:25,  6.56s/it, loss=3.87, acc=0.117]Evaluation:  83%|########2 | 57/69 [07:28<01:18,  6.54s/it, loss=3.87, acc=0.117]Evaluation:  83%|########2 | 57/69 [07:35<01:18,  6.54s/it, loss=3.87, acc=0.116]Evaluation:  84%|########4 | 58/69 [07:35<01:12,  6.62s/it, loss=3.87, acc=0.116]Evaluation:  84%|########4 | 58/69 [07:42<01:12,  6.62s/it, loss=3.87, acc=0.117]Evaluation:  86%|########5 | 59/69 [07:42<01:05,  6.57s/it, loss=3.87, acc=0.117]Evaluation:  86%|########5 | 59/69 [07:48<01:05,  6.57s/it, loss=3.87, acc=0.116]Evaluation:  87%|########6 | 60/69 [07:48<00:59,  6.57s/it, loss=3.87, acc=0.116]Evaluation:  87%|########6 | 60/69 [07:55<00:59,  6.57s/it, loss=3.87, acc=0.116]Evaluation:  88%|########8 | 61/69 [07:55<00:52,  6.56s/it, loss=3.87, acc=0.116]Evaluation:  88%|########8 | 61/69 [08:01<00:52,  6.56s/it, loss=3.87, acc=0.116]Evaluation:  90%|########9 | 62/69 [08:01<00:45,  6.54s/it, loss=3.87, acc=0.116]Evaluation:  90%|########9 | 62/69 [08:08<00:45,  6.54s/it, loss=3.87, acc=0.116]Evaluation:  91%|#########1| 63/69 [08:08<00:39,  6.55s/it, loss=3.87, acc=0.116]Evaluation:  91%|#########1| 63/69 [08:14<00:39,  6.55s/it, loss=3.87, acc=0.116]Evaluation:  93%|#########2| 64/69 [08:14<00:32,  6.55s/it, loss=3.87, acc=0.116]Evaluation:  93%|#########2| 64/69 [08:21<00:32,  6.55s/it, loss=3.88, acc=0.115]Evaluation:  94%|#########4| 65/69 [08:21<00:26,  6.54s/it, loss=3.88, acc=0.115]Evaluation:  94%|#########4| 65/69 [08:27<00:26,  6.54s/it, loss=3.87, acc=0.115]Evaluation:  96%|#########5| 66/69 [08:27<00:19,  6.54s/it, loss=3.87, acc=0.115]Evaluation:  96%|#########5| 66/69 [08:34<00:19,  6.54s/it, loss=3.88, acc=0.115]Evaluation:  97%|#########7| 67/69 [08:34<00:13,  6.54s/it, loss=3.88, acc=0.115]Evaluation:  97%|#########7| 67/69 [08:41<00:13,  6.54s/it, loss=3.88, acc=0.115]Evaluation:  99%|#########8| 68/69 [08:41<00:06,  6.53s/it, loss=3.88, acc=0.115]Evaluation:  99%|#########8| 68/69 [08:46<00:06,  6.53s/it, loss=3.88, acc=0.115]Evaluation: 100%|##########| 69/69 [08:46<00:00,  6.11s/it, loss=3.88, acc=0.115]                                                                                 Evaluation:   0%|          | 0/138 [00:00<?, ?it/s]Evaluation:   0%|          | 0/138 [00:03<?, ?it/s, loss=2.38, acc=0.4]Evaluation:   1%|          | 1/138 [00:03<08:44,  3.83s/it, loss=2.38, acc=0.4]Evaluation:   1%|          | 1/138 [00:07<08:44,  3.83s/it, loss=2.47, acc=0.369]Evaluation:   1%|1         | 2/138 [00:07<08:42,  3.84s/it, loss=2.47, acc=0.369]Evaluation:   1%|1         | 2/138 [00:11<08:42,  3.84s/it, loss=2.34, acc=0.4]  Evaluation:   2%|2         | 3/138 [00:11<08:42,  3.87s/it, loss=2.34, acc=0.4]Evaluation:   2%|2         | 3/138 [00:15<08:42,  3.87s/it, loss=2.42, acc=0.388]Evaluation:   3%|2         | 4/138 [00:15<08:36,  3.86s/it, loss=2.42, acc=0.388]Evaluation:   3%|2         | 4/138 [00:19<08:36,  3.86s/it, loss=2.33, acc=0.415]Evaluation:   4%|3         | 5/138 [00:19<08:34,  3.87s/it, loss=2.33, acc=0.415]Evaluation:   4%|3         | 5/138 [00:23<08:34,  3.87s/it, loss=2.31, acc=0.41] Evaluation:   4%|4         | 6/138 [00:23<08:30,  3.87s/it, loss=2.31, acc=0.41]Evaluation:   4%|4         | 6/138 [00:27<08:30,  3.87s/it, loss=2.29, acc=0.414]Evaluation:   5%|5         | 7/138 [00:27<08:26,  3.87s/it, loss=2.29, acc=0.414]Evaluation:   5%|5         | 7/138 [00:30<08:26,  3.87s/it, loss=2.31, acc=0.409]Evaluation:   6%|5         | 8/138 [00:30<08:23,  3.87s/it, loss=2.31, acc=0.409]Evaluation:   6%|5         | 8/138 [00:34<08:23,  3.87s/it, loss=2.34, acc=0.396]Evaluation:   7%|6         | 9/138 [00:34<08:18,  3.87s/it, loss=2.34, acc=0.396]Evaluation:   7%|6         | 9/138 [00:38<08:18,  3.87s/it, loss=2.32, acc=0.396]Evaluation:   7%|7         | 10/138 [00:38<08:14,  3.87s/it, loss=2.32, acc=0.396]Evaluation:   7%|7         | 10/138 [00:42<08:14,  3.87s/it, loss=2.32, acc=0.395]Evaluation:   8%|7         | 11/138 [00:42<08:11,  3.87s/it, loss=2.32, acc=0.395]Evaluation:   8%|7         | 11/138 [00:46<08:11,  3.87s/it, loss=2.33, acc=0.395]Evaluation:   9%|8         | 12/138 [00:46<08:07,  3.87s/it, loss=2.33, acc=0.395]Evaluation:   9%|8         | 12/138 [00:50<08:07,  3.87s/it, loss=2.32, acc=0.396]Evaluation:   9%|9         | 13/138 [00:50<08:03,  3.87s/it, loss=2.32, acc=0.396]Evaluation:   9%|9         | 13/138 [00:54<08:03,  3.87s/it, loss=2.3, acc=0.403] Evaluation:  10%|#         | 14/138 [00:54<07:59,  3.87s/it, loss=2.3, acc=0.403]Evaluation:  10%|#         | 14/138 [00:58<07:59,  3.87s/it, loss=2.29, acc=0.409]Evaluation:  11%|#         | 15/138 [00:58<07:56,  3.88s/it, loss=2.29, acc=0.409]Evaluation:  11%|#         | 15/138 [01:01<07:56,  3.88s/it, loss=2.27, acc=0.412]Evaluation:  12%|#1        | 16/138 [01:01<07:52,  3.87s/it, loss=2.27, acc=0.412]Evaluation:  12%|#1        | 16/138 [01:05<07:52,  3.87s/it, loss=2.28, acc=0.405]Evaluation:  12%|#2        | 17/138 [01:05<07:49,  3.88s/it, loss=2.28, acc=0.405]Evaluation:  12%|#2        | 17/138 [01:09<07:49,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  13%|#3        | 18/138 [01:09<07:45,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  13%|#3        | 18/138 [01:13<07:45,  3.88s/it, loss=2.28, acc=0.403]Evaluation:  14%|#3        | 19/138 [01:13<07:41,  3.88s/it, loss=2.28, acc=0.403]Evaluation:  14%|#3        | 19/138 [01:17<07:41,  3.88s/it, loss=2.28, acc=0.406]Evaluation:  14%|#4        | 20/138 [01:17<07:38,  3.89s/it, loss=2.28, acc=0.406]Evaluation:  14%|#4        | 20/138 [01:21<07:38,  3.89s/it, loss=2.29, acc=0.405]Evaluation:  15%|#5        | 21/138 [01:21<07:34,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  15%|#5        | 21/138 [01:25<07:34,  3.88s/it, loss=2.29, acc=0.404]Evaluation:  16%|#5        | 22/138 [01:25<07:30,  3.89s/it, loss=2.29, acc=0.404]Evaluation:  16%|#5        | 22/138 [01:29<07:30,  3.89s/it, loss=2.28, acc=0.406]Evaluation:  17%|#6        | 23/138 [01:29<07:26,  3.88s/it, loss=2.28, acc=0.406]Evaluation:  17%|#6        | 23/138 [01:32<07:26,  3.88s/it, loss=2.29, acc=0.403]Evaluation:  17%|#7        | 24/138 [01:32<07:21,  3.87s/it, loss=2.29, acc=0.403]Evaluation:  17%|#7        | 24/138 [01:36<07:21,  3.87s/it, loss=2.3, acc=0.401] Evaluation:  18%|#8        | 25/138 [01:36<07:16,  3.86s/it, loss=2.3, acc=0.401]Evaluation:  18%|#8        | 25/138 [01:40<07:16,  3.86s/it, loss=2.3, acc=0.399]Evaluation:  19%|#8        | 26/138 [01:40<07:11,  3.85s/it, loss=2.3, acc=0.399]Evaluation:  19%|#8        | 26/138 [01:44<07:11,  3.85s/it, loss=2.3, acc=0.4]  Evaluation:  20%|#9        | 27/138 [01:44<07:08,  3.86s/it, loss=2.3, acc=0.4]Evaluation:  20%|#9        | 27/138 [01:48<07:08,  3.86s/it, loss=2.3, acc=0.398]Evaluation:  20%|##        | 28/138 [01:48<07:03,  3.85s/it, loss=2.3, acc=0.398]Evaluation:  20%|##        | 28/138 [01:52<07:03,  3.85s/it, loss=2.3, acc=0.397]Evaluation:  21%|##1       | 29/138 [01:52<07:02,  3.87s/it, loss=2.3, acc=0.397]Evaluation:  21%|##1       | 29/138 [01:56<07:02,  3.87s/it, loss=2.31, acc=0.397]Evaluation:  22%|##1       | 30/138 [01:56<06:57,  3.87s/it, loss=2.31, acc=0.397]Evaluation:  22%|##1       | 30/138 [01:59<06:57,  3.87s/it, loss=2.3, acc=0.397] Evaluation:  22%|##2       | 31/138 [01:59<06:55,  3.88s/it, loss=2.3, acc=0.397]Evaluation:  22%|##2       | 31/138 [02:03<06:55,  3.88s/it, loss=2.3, acc=0.395]Evaluation:  23%|##3       | 32/138 [02:03<06:49,  3.87s/it, loss=2.3, acc=0.395]Evaluation:  23%|##3       | 32/138 [02:07<06:49,  3.87s/it, loss=2.3, acc=0.395]Evaluation:  24%|##3       | 33/138 [02:07<06:46,  3.87s/it, loss=2.3, acc=0.395]Evaluation:  24%|##3       | 33/138 [02:11<06:46,  3.87s/it, loss=2.29, acc=0.395]Evaluation:  25%|##4       | 34/138 [02:11<06:42,  3.87s/it, loss=2.29, acc=0.395]Evaluation:  25%|##4       | 34/138 [02:15<06:42,  3.87s/it, loss=2.3, acc=0.394] Evaluation:  25%|##5       | 35/138 [02:15<06:39,  3.88s/it, loss=2.3, acc=0.394]Evaluation:  25%|##5       | 35/138 [02:19<06:39,  3.88s/it, loss=2.3, acc=0.396]Evaluation:  26%|##6       | 36/138 [02:19<06:34,  3.87s/it, loss=2.3, acc=0.396]Evaluation:  26%|##6       | 36/138 [02:23<06:34,  3.87s/it, loss=2.29, acc=0.397]Evaluation:  27%|##6       | 37/138 [02:23<06:30,  3.86s/it, loss=2.29, acc=0.397]Evaluation:  27%|##6       | 37/138 [02:27<06:30,  3.86s/it, loss=2.29, acc=0.399]Evaluation:  28%|##7       | 38/138 [02:27<06:26,  3.86s/it, loss=2.29, acc=0.399]Evaluation:  28%|##7       | 38/138 [02:30<06:26,  3.86s/it, loss=2.29, acc=0.399]Evaluation:  28%|##8       | 39/138 [02:30<06:23,  3.88s/it, loss=2.29, acc=0.399]Evaluation:  28%|##8       | 39/138 [02:34<06:23,  3.88s/it, loss=2.28, acc=0.4]  Evaluation:  29%|##8       | 40/138 [02:34<06:19,  3.87s/it, loss=2.28, acc=0.4]Evaluation:  29%|##8       | 40/138 [02:38<06:19,  3.87s/it, loss=2.29, acc=0.399]Evaluation:  30%|##9       | 41/138 [02:38<06:14,  3.86s/it, loss=2.29, acc=0.399]Evaluation:  30%|##9       | 41/138 [02:42<06:14,  3.86s/it, loss=2.29, acc=0.398]Evaluation:  30%|###       | 42/138 [02:42<06:10,  3.85s/it, loss=2.29, acc=0.398]Evaluation:  30%|###       | 42/138 [02:46<06:10,  3.85s/it, loss=2.29, acc=0.399]Evaluation:  31%|###1      | 43/138 [02:46<06:07,  3.86s/it, loss=2.29, acc=0.399]Evaluation:  31%|###1      | 43/138 [02:50<06:07,  3.86s/it, loss=2.29, acc=0.399]Evaluation:  32%|###1      | 44/138 [02:50<06:04,  3.87s/it, loss=2.29, acc=0.399]Evaluation:  32%|###1      | 44/138 [02:54<06:04,  3.87s/it, loss=2.28, acc=0.401]Evaluation:  33%|###2      | 45/138 [02:54<06:00,  3.88s/it, loss=2.28, acc=0.401]Evaluation:  33%|###2      | 45/138 [02:58<06:00,  3.88s/it, loss=2.28, acc=0.403]Evaluation:  33%|###3      | 46/138 [02:58<05:57,  3.88s/it, loss=2.28, acc=0.403]Evaluation:  33%|###3      | 46/138 [03:01<05:57,  3.88s/it, loss=2.29, acc=0.401]Evaluation:  34%|###4      | 47/138 [03:01<05:53,  3.88s/it, loss=2.29, acc=0.401]Evaluation:  34%|###4      | 47/138 [03:05<05:53,  3.88s/it, loss=2.29, acc=0.4]  Evaluation:  35%|###4      | 48/138 [03:05<05:49,  3.88s/it, loss=2.29, acc=0.4]Evaluation:  35%|###4      | 48/138 [03:09<05:49,  3.88s/it, loss=2.29, acc=0.401]Evaluation:  36%|###5      | 49/138 [03:09<05:44,  3.87s/it, loss=2.29, acc=0.401]Evaluation:  36%|###5      | 49/138 [03:13<05:44,  3.87s/it, loss=2.29, acc=0.401]Evaluation:  36%|###6      | 50/138 [03:13<05:41,  3.88s/it, loss=2.29, acc=0.401]Evaluation:  36%|###6      | 50/138 [03:17<05:41,  3.88s/it, loss=2.29, acc=0.401]Evaluation:  37%|###6      | 51/138 [03:17<05:37,  3.88s/it, loss=2.29, acc=0.401]Evaluation:  37%|###6      | 51/138 [03:21<05:37,  3.88s/it, loss=2.28, acc=0.402]Evaluation:  38%|###7      | 52/138 [03:21<05:34,  3.89s/it, loss=2.28, acc=0.402]Evaluation:  38%|###7      | 52/138 [03:25<05:34,  3.89s/it, loss=2.28, acc=0.402]Evaluation:  38%|###8      | 53/138 [03:25<05:29,  3.88s/it, loss=2.28, acc=0.402]Evaluation:  38%|###8      | 53/138 [03:29<05:29,  3.88s/it, loss=2.28, acc=0.402]Evaluation:  39%|###9      | 54/138 [03:29<05:26,  3.88s/it, loss=2.28, acc=0.402]Evaluation:  39%|###9      | 54/138 [03:32<05:26,  3.88s/it, loss=2.28, acc=0.402]Evaluation:  40%|###9      | 55/138 [03:32<05:22,  3.89s/it, loss=2.28, acc=0.402]Evaluation:  40%|###9      | 55/138 [03:36<05:22,  3.89s/it, loss=2.28, acc=0.402]Evaluation:  41%|####      | 56/138 [03:36<05:19,  3.89s/it, loss=2.28, acc=0.402]Evaluation:  41%|####      | 56/138 [03:40<05:19,  3.89s/it, loss=2.29, acc=0.402]Evaluation:  41%|####1     | 57/138 [03:40<05:14,  3.89s/it, loss=2.29, acc=0.402]Evaluation:  41%|####1     | 57/138 [03:44<05:14,  3.89s/it, loss=2.28, acc=0.403]Evaluation:  42%|####2     | 58/138 [03:44<05:10,  3.89s/it, loss=2.28, acc=0.403]Evaluation:  42%|####2     | 58/138 [03:48<05:10,  3.89s/it, loss=2.28, acc=0.403]Evaluation:  43%|####2     | 59/138 [03:48<05:05,  3.87s/it, loss=2.28, acc=0.403]Evaluation:  43%|####2     | 59/138 [03:52<05:05,  3.87s/it, loss=2.29, acc=0.402]Evaluation:  43%|####3     | 60/138 [03:52<05:02,  3.87s/it, loss=2.29, acc=0.402]Evaluation:  43%|####3     | 60/138 [03:56<05:02,  3.87s/it, loss=2.29, acc=0.4]  Evaluation:  44%|####4     | 61/138 [03:56<04:58,  3.88s/it, loss=2.29, acc=0.4]Evaluation:  44%|####4     | 61/138 [04:00<04:58,  3.88s/it, loss=2.28, acc=0.401]Evaluation:  45%|####4     | 62/138 [04:00<04:55,  3.89s/it, loss=2.28, acc=0.401]Evaluation:  45%|####4     | 62/138 [04:04<04:55,  3.89s/it, loss=2.29, acc=0.4]  Evaluation:  46%|####5     | 63/138 [04:04<04:51,  3.89s/it, loss=2.29, acc=0.4]Evaluation:  46%|####5     | 63/138 [04:07<04:51,  3.89s/it, loss=2.29, acc=0.4]Evaluation:  46%|####6     | 64/138 [04:07<04:47,  3.89s/it, loss=2.29, acc=0.4]Evaluation:  46%|####6     | 64/138 [04:11<04:47,  3.89s/it, loss=2.29, acc=0.401]Evaluation:  47%|####7     | 65/138 [04:11<04:44,  3.90s/it, loss=2.29, acc=0.401]Evaluation:  47%|####7     | 65/138 [04:15<04:44,  3.90s/it, loss=2.29, acc=0.401]Evaluation:  48%|####7     | 66/138 [04:15<04:40,  3.90s/it, loss=2.29, acc=0.401]Evaluation:  48%|####7     | 66/138 [04:19<04:40,  3.90s/it, loss=2.29, acc=0.401]Evaluation:  49%|####8     | 67/138 [04:19<04:37,  3.91s/it, loss=2.29, acc=0.401]Evaluation:  49%|####8     | 67/138 [04:23<04:37,  3.91s/it, loss=2.29, acc=0.402]Evaluation:  49%|####9     | 68/138 [04:23<04:34,  3.91s/it, loss=2.29, acc=0.402]Evaluation:  49%|####9     | 68/138 [04:27<04:34,  3.91s/it, loss=2.3, acc=0.401] Evaluation:  50%|#####     | 69/138 [04:27<04:29,  3.91s/it, loss=2.3, acc=0.401]Evaluation:  50%|#####     | 69/138 [04:31<04:29,  3.91s/it, loss=2.3, acc=0.402]Evaluation:  51%|#####     | 70/138 [04:31<04:25,  3.90s/it, loss=2.3, acc=0.402]Evaluation:  51%|#####     | 70/138 [04:35<04:25,  3.90s/it, loss=2.3, acc=0.402]Evaluation:  51%|#####1    | 71/138 [04:35<04:21,  3.90s/it, loss=2.3, acc=0.402]Evaluation:  51%|#####1    | 71/138 [04:39<04:21,  3.90s/it, loss=2.3, acc=0.402]Evaluation:  52%|#####2    | 72/138 [04:39<04:16,  3.89s/it, loss=2.3, acc=0.402]Evaluation:  52%|#####2    | 72/138 [04:43<04:16,  3.89s/it, loss=2.29, acc=0.403]Evaluation:  53%|#####2    | 73/138 [04:43<04:12,  3.88s/it, loss=2.29, acc=0.403]Evaluation:  53%|#####2    | 73/138 [04:46<04:12,  3.88s/it, loss=2.29, acc=0.404]Evaluation:  54%|#####3    | 74/138 [04:46<04:08,  3.88s/it, loss=2.29, acc=0.404]Evaluation:  54%|#####3    | 74/138 [04:50<04:08,  3.88s/it, loss=2.29, acc=0.404]Evaluation:  54%|#####4    | 75/138 [04:50<04:04,  3.89s/it, loss=2.29, acc=0.404]Evaluation:  54%|#####4    | 75/138 [04:54<04:04,  3.89s/it, loss=2.29, acc=0.405]Evaluation:  55%|#####5    | 76/138 [04:54<04:00,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  55%|#####5    | 76/138 [04:58<04:00,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  56%|#####5    | 77/138 [04:58<03:56,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  56%|#####5    | 77/138 [05:02<03:56,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  57%|#####6    | 78/138 [05:02<03:52,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  57%|#####6    | 78/138 [05:06<03:52,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  57%|#####7    | 79/138 [05:06<03:48,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  57%|#####7    | 79/138 [05:10<03:48,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  58%|#####7    | 80/138 [05:10<03:45,  3.89s/it, loss=2.29, acc=0.405]Evaluation:  58%|#####7    | 80/138 [05:14<03:45,  3.89s/it, loss=2.29, acc=0.407]Evaluation:  59%|#####8    | 81/138 [05:14<03:41,  3.89s/it, loss=2.29, acc=0.407]Evaluation:  59%|#####8    | 81/138 [05:17<03:41,  3.89s/it, loss=2.29, acc=0.406]Evaluation:  59%|#####9    | 82/138 [05:17<03:37,  3.89s/it, loss=2.29, acc=0.406]Evaluation:  59%|#####9    | 82/138 [05:21<03:37,  3.89s/it, loss=2.29, acc=0.407]Evaluation:  60%|######    | 83/138 [05:21<03:34,  3.89s/it, loss=2.29, acc=0.407]Evaluation:  60%|######    | 83/138 [05:25<03:34,  3.89s/it, loss=2.3, acc=0.406] Evaluation:  61%|######    | 84/138 [05:25<03:30,  3.90s/it, loss=2.3, acc=0.406]Evaluation:  61%|######    | 84/138 [05:29<03:30,  3.90s/it, loss=2.3, acc=0.405]Evaluation:  62%|######1   | 85/138 [05:29<03:26,  3.89s/it, loss=2.3, acc=0.405]Evaluation:  62%|######1   | 85/138 [05:33<03:26,  3.89s/it, loss=2.3, acc=0.405]Evaluation:  62%|######2   | 86/138 [05:33<03:21,  3.88s/it, loss=2.3, acc=0.405]Evaluation:  62%|######2   | 86/138 [05:37<03:21,  3.88s/it, loss=2.3, acc=0.405]Evaluation:  63%|######3   | 87/138 [05:37<03:17,  3.87s/it, loss=2.3, acc=0.405]Evaluation:  63%|######3   | 87/138 [05:41<03:17,  3.87s/it, loss=2.3, acc=0.404]Evaluation:  64%|######3   | 88/138 [05:41<03:13,  3.87s/it, loss=2.3, acc=0.404]Evaluation:  64%|######3   | 88/138 [05:45<03:13,  3.87s/it, loss=2.3, acc=0.405]Evaluation:  64%|######4   | 89/138 [05:45<03:09,  3.87s/it, loss=2.3, acc=0.405]Evaluation:  64%|######4   | 89/138 [05:48<03:09,  3.87s/it, loss=2.3, acc=0.406]Evaluation:  65%|######5   | 90/138 [05:48<03:05,  3.87s/it, loss=2.3, acc=0.406]Evaluation:  65%|######5   | 90/138 [05:52<03:05,  3.87s/it, loss=2.3, acc=0.405]Evaluation:  66%|######5   | 91/138 [05:52<03:02,  3.88s/it, loss=2.3, acc=0.405]Evaluation:  66%|######5   | 91/138 [05:56<03:02,  3.88s/it, loss=2.3, acc=0.405]Evaluation:  67%|######6   | 92/138 [05:56<02:59,  3.90s/it, loss=2.3, acc=0.405]Evaluation:  67%|######6   | 92/138 [06:00<02:59,  3.90s/it, loss=2.3, acc=0.405]Evaluation:  67%|######7   | 93/138 [06:00<02:55,  3.89s/it, loss=2.3, acc=0.405]Evaluation:  67%|######7   | 93/138 [06:04<02:55,  3.89s/it, loss=2.3, acc=0.405]Evaluation:  68%|######8   | 94/138 [06:04<02:50,  3.88s/it, loss=2.3, acc=0.405]Evaluation:  68%|######8   | 94/138 [06:08<02:50,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  69%|######8   | 95/138 [06:08<02:47,  3.89s/it, loss=2.29, acc=0.406]Evaluation:  69%|######8   | 95/138 [06:12<02:47,  3.89s/it, loss=2.29, acc=0.406]Evaluation:  70%|######9   | 96/138 [06:12<02:42,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  70%|######9   | 96/138 [06:16<02:42,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  70%|#######   | 97/138 [06:16<02:39,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  70%|#######   | 97/138 [06:20<02:39,  3.88s/it, loss=2.3, acc=0.406] Evaluation:  71%|#######1  | 98/138 [06:20<02:35,  3.89s/it, loss=2.3, acc=0.406]Evaluation:  71%|#######1  | 98/138 [06:23<02:35,  3.89s/it, loss=2.3, acc=0.405]Evaluation:  72%|#######1  | 99/138 [06:23<02:31,  3.88s/it, loss=2.3, acc=0.405]Evaluation:  72%|#######1  | 99/138 [06:27<02:31,  3.88s/it, loss=2.3, acc=0.405]Evaluation:  72%|#######2  | 100/138 [06:27<02:27,  3.88s/it, loss=2.3, acc=0.405]Evaluation:  72%|#######2  | 100/138 [06:31<02:27,  3.88s/it, loss=2.3, acc=0.405]Evaluation:  73%|#######3  | 101/138 [06:31<02:23,  3.88s/it, loss=2.3, acc=0.405]Evaluation:  73%|#######3  | 101/138 [06:35<02:23,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  74%|#######3  | 102/138 [06:35<02:19,  3.87s/it, loss=2.29, acc=0.405]Evaluation:  74%|#######3  | 102/138 [06:39<02:19,  3.87s/it, loss=2.29, acc=0.405]Evaluation:  75%|#######4  | 103/138 [06:39<02:15,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  75%|#######4  | 103/138 [06:43<02:15,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  75%|#######5  | 104/138 [06:43<02:11,  3.87s/it, loss=2.29, acc=0.405]Evaluation:  75%|#######5  | 104/138 [06:47<02:11,  3.87s/it, loss=2.29, acc=0.405]Evaluation:  76%|#######6  | 105/138 [06:47<02:08,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  76%|#######6  | 105/138 [06:51<02:08,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  77%|#######6  | 106/138 [06:51<02:04,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  77%|#######6  | 106/138 [06:55<02:04,  3.88s/it, loss=2.29, acc=0.406]Evaluation:  78%|#######7  | 107/138 [06:55<02:00,  3.89s/it, loss=2.29, acc=0.406]Evaluation:  78%|#######7  | 107/138 [06:58<02:00,  3.89s/it, loss=2.29, acc=0.405]Evaluation:  78%|#######8  | 108/138 [06:58<01:56,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  78%|#######8  | 108/138 [07:02<01:56,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  79%|#######8  | 109/138 [07:02<01:52,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  79%|#######8  | 109/138 [07:06<01:52,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  80%|#######9  | 110/138 [07:06<01:48,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  80%|#######9  | 110/138 [07:10<01:48,  3.88s/it, loss=2.29, acc=0.405]Evaluation:  80%|########  | 111/138 [07:10<01:45,  3.90s/it, loss=2.29, acc=0.405]Evaluation:  80%|########  | 111/138 [07:14<01:45,  3.90s/it, loss=2.29, acc=0.405]Evaluation:  81%|########1 | 112/138 [07:14<01:41,  3.89s/it, loss=2.29, acc=0.405]Evaluation:  81%|########1 | 112/138 [07:18<01:41,  3.89s/it, loss=2.29, acc=0.405]Evaluation:  82%|########1 | 113/138 [07:18<01:37,  3.89s/it, loss=2.29, acc=0.405]Evaluation:  82%|########1 | 113/138 [07:22<01:37,  3.89s/it, loss=2.29, acc=0.404]Evaluation:  83%|########2 | 114/138 [07:22<01:33,  3.89s/it, loss=2.29, acc=0.404]Evaluation:  83%|########2 | 114/138 [07:26<01:33,  3.89s/it, loss=2.29, acc=0.404]Evaluation:  83%|########3 | 115/138 [07:26<01:29,  3.88s/it, loss=2.29, acc=0.404]Evaluation:  83%|########3 | 115/138 [07:30<01:29,  3.88s/it, loss=2.3, acc=0.403] Evaluation:  84%|########4 | 116/138 [07:30<01:25,  3.89s/it, loss=2.3, acc=0.403]Evaluation:  84%|########4 | 116/138 [07:33<01:25,  3.89s/it, loss=2.3, acc=0.403]Evaluation:  85%|########4 | 117/138 [07:33<01:21,  3.89s/it, loss=2.3, acc=0.403]Evaluation:  85%|########4 | 117/138 [07:37<01:21,  3.89s/it, loss=2.3, acc=0.403]Evaluation:  86%|########5 | 118/138 [07:37<01:17,  3.89s/it, loss=2.3, acc=0.403]Evaluation:  86%|########5 | 118/138 [07:41<01:17,  3.89s/it, loss=2.31, acc=0.403]Evaluation:  86%|########6 | 119/138 [07:41<01:13,  3.89s/it, loss=2.31, acc=0.403]Evaluation:  86%|########6 | 119/138 [07:45<01:13,  3.89s/it, loss=2.3, acc=0.403] Evaluation:  87%|########6 | 120/138 [07:45<01:09,  3.89s/it, loss=2.3, acc=0.403]Evaluation:  87%|########6 | 120/138 [07:49<01:09,  3.89s/it, loss=2.3, acc=0.404]Evaluation:  88%|########7 | 121/138 [07:49<01:06,  3.89s/it, loss=2.3, acc=0.404]Evaluation:  88%|########7 | 121/138 [07:53<01:06,  3.89s/it, loss=2.3, acc=0.404]Evaluation:  88%|########8 | 122/138 [07:53<01:02,  3.88s/it, loss=2.3, acc=0.404]Evaluation:  88%|########8 | 122/138 [07:57<01:02,  3.88s/it, loss=2.3, acc=0.404]Evaluation:  89%|########9 | 123/138 [07:57<00:58,  3.87s/it, loss=2.3, acc=0.404]Evaluation:  89%|########9 | 123/138 [08:01<00:58,  3.87s/it, loss=2.3, acc=0.405]Evaluation:  90%|########9 | 124/138 [08:01<00:54,  3.87s/it, loss=2.3, acc=0.405]Evaluation:  90%|########9 | 124/138 [08:04<00:54,  3.87s/it, loss=2.3, acc=0.405]Evaluation:  91%|######### | 125/138 [08:04<00:50,  3.87s/it, loss=2.3, acc=0.405]Evaluation:  91%|######### | 125/138 [08:08<00:50,  3.87s/it, loss=2.3, acc=0.404]Evaluation:  91%|#########1| 126/138 [08:08<00:46,  3.87s/it, loss=2.3, acc=0.404]Evaluation:  91%|#########1| 126/138 [08:12<00:46,  3.87s/it, loss=2.3, acc=0.404]Evaluation:  92%|#########2| 127/138 [08:12<00:42,  3.88s/it, loss=2.3, acc=0.404]Evaluation:  92%|#########2| 127/138 [08:16<00:42,  3.88s/it, loss=2.3, acc=0.404]Evaluation:  93%|#########2| 128/138 [08:16<00:38,  3.89s/it, loss=2.3, acc=0.404]Evaluation:  93%|#########2| 128/138 [08:20<00:38,  3.89s/it, loss=2.3, acc=0.403]Evaluation:  93%|#########3| 129/138 [08:20<00:34,  3.89s/it, loss=2.3, acc=0.403]Evaluation:  93%|#########3| 129/138 [08:24<00:34,  3.89s/it, loss=2.31, acc=0.404]Evaluation:  94%|#########4| 130/138 [08:24<00:31,  3.89s/it, loss=2.31, acc=0.404]Evaluation:  94%|#########4| 130/138 [08:28<00:31,  3.89s/it, loss=2.31, acc=0.404]Evaluation:  95%|#########4| 131/138 [08:28<00:27,  3.90s/it, loss=2.31, acc=0.404]Evaluation:  95%|#########4| 131/138 [08:32<00:27,  3.90s/it, loss=2.31, acc=0.404]Evaluation:  96%|#########5| 132/138 [08:32<00:23,  3.90s/it, loss=2.31, acc=0.404]Evaluation:  96%|#########5| 132/138 [08:36<00:23,  3.90s/it, loss=2.31, acc=0.403]Evaluation:  96%|#########6| 133/138 [08:36<00:19,  3.89s/it, loss=2.31, acc=0.403]Evaluation:  96%|#########6| 133/138 [08:39<00:19,  3.89s/it, loss=2.31, acc=0.403]Evaluation:  97%|#########7| 134/138 [08:39<00:15,  3.89s/it, loss=2.31, acc=0.403]Evaluation:  97%|#########7| 134/138 [08:43<00:15,  3.89s/it, loss=2.31, acc=0.403]Evaluation:  98%|#########7| 135/138 [08:43<00:11,  3.89s/it, loss=2.31, acc=0.403]Evaluation:  98%|#########7| 135/138 [08:47<00:11,  3.89s/it, loss=2.31, acc=0.403]Evaluation:  99%|#########8| 136/138 [08:47<00:07,  3.90s/it, loss=2.31, acc=0.403]Evaluation:  99%|#########8| 136/138 [08:51<00:07,  3.90s/it, loss=2.31, acc=0.403]Evaluation:  99%|#########9| 137/138 [08:51<00:03,  3.90s/it, loss=2.31, acc=0.403]Evaluation:  99%|#########9| 137/138 [08:53<00:03,  3.90s/it, loss=2.31, acc=0.403]Evaluation: 100%|##########| 138/138 [08:53<00:00,  3.39s/it, loss=2.31, acc=0.403]                                                                                   Evaluation:   0%|          | 0/276 [00:00<?, ?it/s]Evaluation:   0%|          | 0/276 [00:02<?, ?it/s, loss=0.595, acc=0.775]Evaluation:   0%|          | 1/276 [00:02<11:52,  2.59s/it, loss=0.595, acc=0.775]Evaluation:   0%|          | 1/276 [00:05<11:52,  2.59s/it, loss=0.739, acc=0.788]Evaluation:   1%|          | 2/276 [00:05<11:53,  2.61s/it, loss=0.739, acc=0.788]Evaluation:   1%|          | 2/276 [00:07<11:53,  2.61s/it, loss=0.722, acc=0.792]Evaluation:   1%|1         | 3/276 [00:07<11:47,  2.59s/it, loss=0.722, acc=0.792]Evaluation:   1%|1         | 3/276 [00:10<11:47,  2.59s/it, loss=0.794, acc=0.762]Evaluation:   1%|1         | 4/276 [00:10<11:43,  2.59s/it, loss=0.794, acc=0.762]Evaluation:   1%|1         | 4/276 [00:12<11:43,  2.59s/it, loss=0.809, acc=0.75] Evaluation:   2%|1         | 5/276 [00:12<11:42,  2.59s/it, loss=0.809, acc=0.75]Evaluation:   2%|1         | 5/276 [00:15<11:42,  2.59s/it, loss=0.959, acc=0.708]Evaluation:   2%|2         | 6/276 [00:15<11:38,  2.59s/it, loss=0.959, acc=0.708]Evaluation:   2%|2         | 6/276 [00:18<11:38,  2.59s/it, loss=1.01, acc=0.693] Evaluation:   3%|2         | 7/276 [00:18<11:36,  2.59s/it, loss=1.01, acc=0.693]Evaluation:   3%|2         | 7/276 [00:20<11:36,  2.59s/it, loss=1.11, acc=0.659]Evaluation:   3%|2         | 8/276 [00:20<11:32,  2.59s/it, loss=1.11, acc=0.659]Evaluation:   3%|2         | 8/276 [00:23<11:32,  2.59s/it, loss=1.08, acc=0.667]Evaluation:   3%|3         | 9/276 [00:23<11:32,  2.59s/it, loss=1.08, acc=0.667]Evaluation:   3%|3         | 9/276 [00:25<11:32,  2.59s/it, loss=1.05, acc=0.67] Evaluation:   4%|3         | 10/276 [00:25<11:30,  2.59s/it, loss=1.05, acc=0.67]Evaluation:   4%|3         | 10/276 [00:28<11:30,  2.59s/it, loss=1.11, acc=0.664]Evaluation:   4%|3         | 11/276 [00:28<11:26,  2.59s/it, loss=1.11, acc=0.664]Evaluation:   4%|3         | 11/276 [00:31<11:26,  2.59s/it, loss=1.11, acc=0.663]Evaluation:   4%|4         | 12/276 [00:31<11:24,  2.59s/it, loss=1.11, acc=0.663]Evaluation:   4%|4         | 12/276 [00:33<11:24,  2.59s/it, loss=1.12, acc=0.658]Evaluation:   5%|4         | 13/276 [00:33<11:22,  2.59s/it, loss=1.12, acc=0.658]Evaluation:   5%|4         | 13/276 [00:36<11:22,  2.59s/it, loss=1.1, acc=0.664] Evaluation:   5%|5         | 14/276 [00:36<11:19,  2.59s/it, loss=1.1, acc=0.664]Evaluation:   5%|5         | 14/276 [00:38<11:19,  2.59s/it, loss=1.1, acc=0.663]Evaluation:   5%|5         | 15/276 [00:38<11:16,  2.59s/it, loss=1.1, acc=0.663]Evaluation:   5%|5         | 15/276 [00:41<11:16,  2.59s/it, loss=1.08, acc=0.675]Evaluation:   6%|5         | 16/276 [00:41<11:13,  2.59s/it, loss=1.08, acc=0.675]Evaluation:   6%|5         | 16/276 [00:44<11:13,  2.59s/it, loss=1.09, acc=0.671]Evaluation:   6%|6         | 17/276 [00:44<11:11,  2.59s/it, loss=1.09, acc=0.671]Evaluation:   6%|6         | 17/276 [00:46<11:11,  2.59s/it, loss=1.09, acc=0.674]Evaluation:   7%|6         | 18/276 [00:46<11:08,  2.59s/it, loss=1.09, acc=0.674]Evaluation:   7%|6         | 18/276 [00:49<11:08,  2.59s/it, loss=1.12, acc=0.668]Evaluation:   7%|6         | 19/276 [00:49<11:03,  2.58s/it, loss=1.12, acc=0.668]Evaluation:   7%|6         | 19/276 [00:51<11:03,  2.58s/it, loss=1.11, acc=0.667]Evaluation:   7%|7         | 20/276 [00:51<11:02,  2.59s/it, loss=1.11, acc=0.667]Evaluation:   7%|7         | 20/276 [00:54<11:02,  2.59s/it, loss=1.12, acc=0.667]Evaluation:   8%|7         | 21/276 [00:54<10:59,  2.59s/it, loss=1.12, acc=0.667]Evaluation:   8%|7         | 21/276 [00:56<10:59,  2.59s/it, loss=1.12, acc=0.668]Evaluation:   8%|7         | 22/276 [00:56<10:57,  2.59s/it, loss=1.12, acc=0.668]Evaluation:   8%|7         | 22/276 [00:59<10:57,  2.59s/it, loss=1.11, acc=0.668]Evaluation:   8%|8         | 23/276 [00:59<10:55,  2.59s/it, loss=1.11, acc=0.668]Evaluation:   8%|8         | 23/276 [01:02<10:55,  2.59s/it, loss=1.12, acc=0.669]Evaluation:   9%|8         | 24/276 [01:02<10:53,  2.59s/it, loss=1.12, acc=0.669]Evaluation:   9%|8         | 24/276 [01:04<10:53,  2.59s/it, loss=1.12, acc=0.671]Evaluation:   9%|9         | 25/276 [01:04<10:51,  2.59s/it, loss=1.12, acc=0.671]Evaluation:   9%|9         | 25/276 [01:07<10:51,  2.59s/it, loss=1.12, acc=0.672]Evaluation:   9%|9         | 26/276 [01:07<10:48,  2.60s/it, loss=1.12, acc=0.672]Evaluation:   9%|9         | 26/276 [01:09<10:48,  2.60s/it, loss=1.13, acc=0.67] Evaluation:  10%|9         | 27/276 [01:09<10:47,  2.60s/it, loss=1.13, acc=0.67]Evaluation:  10%|9         | 27/276 [01:12<10:47,  2.60s/it, loss=1.13, acc=0.673]Evaluation:  10%|#         | 28/276 [01:12<10:45,  2.60s/it, loss=1.13, acc=0.673]Evaluation:  10%|#         | 28/276 [01:15<10:45,  2.60s/it, loss=1.13, acc=0.674]Evaluation:  11%|#         | 29/276 [01:15<10:42,  2.60s/it, loss=1.13, acc=0.674]Evaluation:  11%|#         | 29/276 [01:17<10:42,  2.60s/it, loss=1.13, acc=0.671]Evaluation:  11%|#         | 30/276 [01:17<10:40,  2.60s/it, loss=1.13, acc=0.671]Evaluation:  11%|#         | 30/276 [01:20<10:40,  2.60s/it, loss=1.13, acc=0.671]Evaluation:  11%|#1        | 31/276 [01:20<10:38,  2.61s/it, loss=1.13, acc=0.671]Evaluation:  11%|#1        | 31/276 [01:23<10:38,  2.61s/it, loss=1.12, acc=0.67] Evaluation:  12%|#1        | 32/276 [01:23<10:35,  2.61s/it, loss=1.12, acc=0.67]Evaluation:  12%|#1        | 32/276 [01:25<10:35,  2.61s/it, loss=1.12, acc=0.669]Evaluation:  12%|#1        | 33/276 [01:25<10:32,  2.60s/it, loss=1.12, acc=0.669]Evaluation:  12%|#1        | 33/276 [01:28<10:32,  2.60s/it, loss=1.12, acc=0.671]Evaluation:  12%|#2        | 34/276 [01:28<10:29,  2.60s/it, loss=1.12, acc=0.671]Evaluation:  12%|#2        | 34/276 [01:30<10:29,  2.60s/it, loss=1.13, acc=0.669]Evaluation:  13%|#2        | 35/276 [01:30<10:27,  2.60s/it, loss=1.13, acc=0.669]Evaluation:  13%|#2        | 35/276 [01:33<10:27,  2.60s/it, loss=1.13, acc=0.671]Evaluation:  13%|#3        | 36/276 [01:33<10:23,  2.60s/it, loss=1.13, acc=0.671]Evaluation:  13%|#3        | 36/276 [01:35<10:23,  2.60s/it, loss=1.13, acc=0.67] Evaluation:  13%|#3        | 37/276 [01:35<10:18,  2.59s/it, loss=1.13, acc=0.67]Evaluation:  13%|#3        | 37/276 [01:38<10:18,  2.59s/it, loss=1.14, acc=0.668]Evaluation:  14%|#3        | 38/276 [01:38<10:15,  2.59s/it, loss=1.14, acc=0.668]Evaluation:  14%|#3        | 38/276 [01:41<10:15,  2.59s/it, loss=1.14, acc=0.667]Evaluation:  14%|#4        | 39/276 [01:41<10:14,  2.59s/it, loss=1.14, acc=0.667]Evaluation:  14%|#4        | 39/276 [01:43<10:14,  2.59s/it, loss=1.14, acc=0.666]Evaluation:  14%|#4        | 40/276 [01:43<10:13,  2.60s/it, loss=1.14, acc=0.666]Evaluation:  14%|#4        | 40/276 [01:46<10:13,  2.60s/it, loss=1.14, acc=0.667]Evaluation:  15%|#4        | 41/276 [01:46<10:09,  2.59s/it, loss=1.14, acc=0.667]Evaluation:  15%|#4        | 41/276 [01:48<10:09,  2.59s/it, loss=1.15, acc=0.665]Evaluation:  15%|#5        | 42/276 [01:48<10:05,  2.59s/it, loss=1.15, acc=0.665]Evaluation:  15%|#5        | 42/276 [01:51<10:05,  2.59s/it, loss=1.14, acc=0.667]Evaluation:  16%|#5        | 43/276 [01:51<10:02,  2.59s/it, loss=1.14, acc=0.667]Evaluation:  16%|#5        | 43/276 [01:54<10:02,  2.59s/it, loss=1.14, acc=0.667]Evaluation:  16%|#5        | 44/276 [01:54<10:00,  2.59s/it, loss=1.14, acc=0.667]Evaluation:  16%|#5        | 44/276 [01:56<10:00,  2.59s/it, loss=1.14, acc=0.667]Evaluation:  16%|#6        | 45/276 [01:56<09:57,  2.58s/it, loss=1.14, acc=0.667]Evaluation:  16%|#6        | 45/276 [01:59<09:57,  2.58s/it, loss=1.15, acc=0.663]Evaluation:  17%|#6        | 46/276 [01:59<09:54,  2.59s/it, loss=1.15, acc=0.663]Evaluation:  17%|#6        | 46/276 [02:01<09:54,  2.59s/it, loss=1.16, acc=0.661]Evaluation:  17%|#7        | 47/276 [02:01<09:53,  2.59s/it, loss=1.16, acc=0.661]Evaluation:  17%|#7        | 47/276 [02:04<09:53,  2.59s/it, loss=1.16, acc=0.661]Evaluation:  17%|#7        | 48/276 [02:04<09:50,  2.59s/it, loss=1.16, acc=0.661]Evaluation:  17%|#7        | 48/276 [02:07<09:50,  2.59s/it, loss=1.16, acc=0.659]Evaluation:  18%|#7        | 49/276 [02:07<09:47,  2.59s/it, loss=1.16, acc=0.659]Evaluation:  18%|#7        | 49/276 [02:09<09:47,  2.59s/it, loss=1.17, acc=0.659]Evaluation:  18%|#8        | 50/276 [02:09<09:45,  2.59s/it, loss=1.17, acc=0.659]Evaluation:  18%|#8        | 50/276 [02:12<09:45,  2.59s/it, loss=1.17, acc=0.659]Evaluation:  18%|#8        | 51/276 [02:12<09:43,  2.59s/it, loss=1.17, acc=0.659]Evaluation:  18%|#8        | 51/276 [02:14<09:43,  2.59s/it, loss=1.17, acc=0.66] Evaluation:  19%|#8        | 52/276 [02:14<09:42,  2.60s/it, loss=1.17, acc=0.66]Evaluation:  19%|#8        | 52/276 [02:17<09:42,  2.60s/it, loss=1.17, acc=0.659]Evaluation:  19%|#9        | 53/276 [02:17<09:40,  2.60s/it, loss=1.17, acc=0.659]Evaluation:  19%|#9        | 53/276 [02:20<09:40,  2.60s/it, loss=1.17, acc=0.658]Evaluation:  20%|#9        | 54/276 [02:20<09:38,  2.61s/it, loss=1.17, acc=0.658]Evaluation:  20%|#9        | 54/276 [02:22<09:38,  2.61s/it, loss=1.17, acc=0.657]Evaluation:  20%|#9        | 55/276 [02:22<09:36,  2.61s/it, loss=1.17, acc=0.657]Evaluation:  20%|#9        | 55/276 [02:25<09:36,  2.61s/it, loss=1.17, acc=0.658]Evaluation:  20%|##        | 56/276 [02:25<09:34,  2.61s/it, loss=1.17, acc=0.658]Evaluation:  20%|##        | 56/276 [02:27<09:34,  2.61s/it, loss=1.17, acc=0.655]Evaluation:  21%|##        | 57/276 [02:27<09:31,  2.61s/it, loss=1.17, acc=0.655]Evaluation:  21%|##        | 57/276 [02:30<09:31,  2.61s/it, loss=1.17, acc=0.654]Evaluation:  21%|##1       | 58/276 [02:30<09:27,  2.60s/it, loss=1.17, acc=0.654]Evaluation:  21%|##1       | 58/276 [02:33<09:27,  2.60s/it, loss=1.17, acc=0.656]Evaluation:  21%|##1       | 59/276 [02:33<09:23,  2.60s/it, loss=1.17, acc=0.656]Evaluation:  21%|##1       | 59/276 [02:35<09:23,  2.60s/it, loss=1.17, acc=0.655]Evaluation:  22%|##1       | 60/276 [02:35<09:20,  2.60s/it, loss=1.17, acc=0.655]Evaluation:  22%|##1       | 60/276 [02:38<09:20,  2.60s/it, loss=1.17, acc=0.655]Evaluation:  22%|##2       | 61/276 [02:38<09:18,  2.60s/it, loss=1.17, acc=0.655]Evaluation:  22%|##2       | 61/276 [02:40<09:18,  2.60s/it, loss=1.17, acc=0.656]Evaluation:  22%|##2       | 62/276 [02:40<09:14,  2.59s/it, loss=1.17, acc=0.656]                                                                                  Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 30, in evaluate
    assert not torch.tensor(prediction).isnan().any()
KeyboardInterrupt
Evaluation:   0%|          | 0/32 [00:00<?, ?it/s]/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=100
  warnings.warn(
/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=128 is too small for input signal of length=50
  warnings.warn(
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_norm = torch.tensor(X_norm)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/32 [00:16<?, ?it/s, loss=4.84, acc=0.0531]Evaluation:   3%|3         | 1/32 [00:16<08:24, 16.27s/it, loss=4.84, acc=0.0531]                                                                                 Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 97, in transform
    X = constant_q(
  File "/geode2/home/u080/skarukas/Carbonate/SITH/util.py", line 180, in constant_q
    X = librosa.cqt(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 185, in cqt
    return vqt(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 1005, in vqt
    my_y = audio.resample(my_y, 2, 1, res_type=res_type, scale=True)
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/audio.py", line 604, in resample
    y_hat = resampy.resample(y, orig_sr, target_sr, filter=res_type, axis=-1)
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/resampy/core.py", line 109, in resample
    interp_win, precision, _ = get_filter(filter, **kwargs)
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/resampy/filters.py", line 164, in get_filter
    return load_filter(name_or_function)
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/resampy/filters.py", line 193, in load_filter
    data = np.load(pkg_resources.resource_filename(__name__, fname))
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/pkg_resources/__init__.py", line 1135, in resource_filename
    return get_provider(package_or_requirement).get_resource_filename(
KeyboardInterrupt
Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_norm = torch.tensor(X_norm)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/125 [00:05<?, ?it/s, loss=2.57, acc=0.375]Evaluation:   1%|          | 1/125 [00:05<11:19,  5.48s/it, loss=2.57, acc=0.375]Evaluation:   1%|          | 1/125 [00:10<11:19,  5.48s/it, loss=2.34, acc=0.381]Evaluation:   2%|1         | 2/125 [00:10<10:13,  4.99s/it, loss=2.34, acc=0.381]Evaluation:   2%|1         | 2/125 [00:14<10:13,  4.99s/it, loss=2.23, acc=0.417]Evaluation:   2%|2         | 3/125 [00:14<09:38,  4.75s/it, loss=2.23, acc=0.417]Evaluation:   2%|2         | 3/125 [00:19<09:38,  4.75s/it, loss=2.2, acc=0.409] Evaluation:   3%|3         | 4/125 [00:19<09:28,  4.70s/it, loss=2.2, acc=0.409]Evaluation:   3%|3         | 4/125 [00:23<09:28,  4.70s/it, loss=2.26, acc=0.4] Evaluation:   4%|4         | 5/125 [00:23<09:21,  4.68s/it, loss=2.26, acc=0.4]Evaluation:   4%|4         | 5/125 [00:28<09:21,  4.68s/it, loss=2.28, acc=0.404]Evaluation:   5%|4         | 6/125 [00:28<09:10,  4.62s/it, loss=2.28, acc=0.404]Evaluation:   5%|4         | 6/125 [00:32<09:10,  4.62s/it, loss=2.24, acc=0.402]Evaluation:   6%|5         | 7/125 [00:32<08:57,  4.56s/it, loss=2.24, acc=0.402]Evaluation:   6%|5         | 7/125 [00:37<08:57,  4.56s/it, loss=2.24, acc=0.406]Evaluation:   6%|6         | 8/125 [00:37<08:52,  4.55s/it, loss=2.24, acc=0.406]Evaluation:   6%|6         | 8/125 [00:41<08:52,  4.55s/it, loss=2.22, acc=0.396]Evaluation:   7%|7         | 9/125 [00:41<08:41,  4.50s/it, loss=2.22, acc=0.396]Evaluation:   7%|7         | 9/125 [00:46<08:41,  4.50s/it, loss=2.26, acc=0.4]  Evaluation:   8%|8         | 10/125 [00:46<08:40,  4.52s/it, loss=2.26, acc=0.4]Evaluation:   8%|8         | 10/125 [00:50<08:40,  4.52s/it, loss=2.25, acc=0.402]Evaluation:   9%|8         | 11/125 [00:50<08:33,  4.50s/it, loss=2.25, acc=0.402]Evaluation:   9%|8         | 11/125 [00:55<08:33,  4.50s/it, loss=2.24, acc=0.406]Evaluation:  10%|9         | 12/125 [00:55<08:28,  4.50s/it, loss=2.24, acc=0.406]Evaluation:  10%|9         | 12/125 [00:59<08:28,  4.50s/it, loss=2.2, acc=0.413] Evaluation:  10%|#         | 13/125 [00:59<08:18,  4.45s/it, loss=2.2, acc=0.413]Evaluation:  10%|#         | 13/125 [01:04<08:18,  4.45s/it, loss=2.23, acc=0.41]Evaluation:  11%|#1        | 14/125 [01:04<08:20,  4.51s/it, loss=2.23, acc=0.41]Evaluation:  11%|#1        | 14/125 [01:08<08:20,  4.51s/it, loss=2.23, acc=0.406]Evaluation:  12%|#2        | 15/125 [01:08<08:19,  4.54s/it, loss=2.23, acc=0.406]Evaluation:  12%|#2        | 15/125 [01:13<08:19,  4.54s/it, loss=2.25, acc=0.402]Evaluation:  13%|#2        | 16/125 [01:13<08:13,  4.53s/it, loss=2.25, acc=0.402]Evaluation:  13%|#2        | 16/125 [01:17<08:13,  4.53s/it, loss=2.25, acc=0.405]Evaluation:  14%|#3        | 17/125 [01:17<08:12,  4.56s/it, loss=2.25, acc=0.405]Evaluation:  14%|#3        | 17/125 [01:22<08:12,  4.56s/it, loss=2.23, acc=0.409]Evaluation:  14%|#4        | 18/125 [01:22<08:08,  4.57s/it, loss=2.23, acc=0.409]Evaluation:  14%|#4        | 18/125 [01:27<08:08,  4.57s/it, loss=2.25, acc=0.405]Evaluation:  15%|#5        | 19/125 [01:27<08:01,  4.54s/it, loss=2.25, acc=0.405]Evaluation:  15%|#5        | 19/125 [01:31<08:01,  4.54s/it, loss=2.28, acc=0.403]Evaluation:  16%|#6        | 20/125 [01:31<07:59,  4.57s/it, loss=2.28, acc=0.403]Evaluation:  16%|#6        | 20/125 [01:36<07:59,  4.57s/it, loss=2.28, acc=0.402]Evaluation:  17%|#6        | 21/125 [01:36<07:52,  4.54s/it, loss=2.28, acc=0.402]Evaluation:  17%|#6        | 21/125 [01:40<07:52,  4.54s/it, loss=2.28, acc=0.403]Evaluation:  18%|#7        | 22/125 [01:40<07:52,  4.59s/it, loss=2.28, acc=0.403]Evaluation:  18%|#7        | 22/125 [01:45<07:52,  4.59s/it, loss=2.27, acc=0.403]Evaluation:  18%|#8        | 23/125 [01:45<07:46,  4.57s/it, loss=2.27, acc=0.403]Evaluation:  18%|#8        | 23/125 [01:50<07:46,  4.57s/it, loss=2.27, acc=0.405]Evaluation:  19%|#9        | 24/125 [01:50<07:44,  4.60s/it, loss=2.27, acc=0.405]Evaluation:  19%|#9        | 24/125 [01:54<07:44,  4.60s/it, loss=2.29, acc=0.403]Evaluation:  20%|##        | 25/125 [01:54<07:40,  4.60s/it, loss=2.29, acc=0.403]Evaluation:  20%|##        | 25/125 [01:59<07:40,  4.60s/it, loss=2.28, acc=0.405]Evaluation:  21%|##        | 26/125 [01:59<07:32,  4.57s/it, loss=2.28, acc=0.405]Evaluation:  21%|##        | 26/125 [02:03<07:32,  4.57s/it, loss=2.3, acc=0.402] Evaluation:  22%|##1       | 27/125 [02:03<07:30,  4.60s/it, loss=2.3, acc=0.402]Evaluation:  22%|##1       | 27/125 [02:08<07:30,  4.60s/it, loss=2.3, acc=0.403]Evaluation:  22%|##2       | 28/125 [02:08<07:30,  4.64s/it, loss=2.3, acc=0.403]Evaluation:  22%|##2       | 28/125 [02:13<07:30,  4.64s/it, loss=2.31, acc=0.402]Evaluation:  23%|##3       | 29/125 [02:13<07:27,  4.66s/it, loss=2.31, acc=0.402]Evaluation:  23%|##3       | 29/125 [02:17<07:27,  4.66s/it, loss=2.3, acc=0.404] Evaluation:  24%|##4       | 30/125 [02:17<07:17,  4.61s/it, loss=2.3, acc=0.404]Evaluation:  24%|##4       | 30/125 [02:22<07:17,  4.61s/it, loss=2.3, acc=0.405]Evaluation:  25%|##4       | 31/125 [02:22<07:12,  4.60s/it, loss=2.3, acc=0.405]Evaluation:  25%|##4       | 31/125 [02:26<07:12,  4.60s/it, loss=2.31, acc=0.403]Evaluation:  26%|##5       | 32/125 [02:26<07:05,  4.58s/it, loss=2.31, acc=0.403]Evaluation:  26%|##5       | 32/125 [02:31<07:05,  4.58s/it, loss=2.32, acc=0.401]Evaluation:  26%|##6       | 33/125 [02:31<06:59,  4.56s/it, loss=2.32, acc=0.401]Evaluation:  26%|##6       | 33/125 [02:35<06:59,  4.56s/it, loss=2.33, acc=0.399]Evaluation:  27%|##7       | 34/125 [02:35<06:55,  4.57s/it, loss=2.33, acc=0.399]Evaluation:  27%|##7       | 34/125 [02:40<06:55,  4.57s/it, loss=2.32, acc=0.401]Evaluation:  28%|##8       | 35/125 [02:40<06:50,  4.56s/it, loss=2.32, acc=0.401]Evaluation:  28%|##8       | 35/125 [02:45<06:50,  4.56s/it, loss=2.32, acc=0.4]  Evaluation:  29%|##8       | 36/125 [02:45<06:44,  4.55s/it, loss=2.32, acc=0.4]Evaluation:  29%|##8       | 36/125 [02:49<06:44,  4.55s/it, loss=2.33, acc=0.399]Evaluation:  30%|##9       | 37/125 [02:49<06:38,  4.53s/it, loss=2.33, acc=0.399]Evaluation:  30%|##9       | 37/125 [02:54<06:38,  4.53s/it, loss=2.33, acc=0.398]Evaluation:  30%|###       | 38/125 [02:54<06:36,  4.56s/it, loss=2.33, acc=0.398]Evaluation:  30%|###       | 38/125 [02:58<06:36,  4.56s/it, loss=2.32, acc=0.399]Evaluation:  31%|###1      | 39/125 [02:58<06:32,  4.56s/it, loss=2.32, acc=0.399]Evaluation:  31%|###1      | 39/125 [03:03<06:32,  4.56s/it, loss=2.33, acc=0.399]Evaluation:  32%|###2      | 40/125 [03:03<06:29,  4.58s/it, loss=2.33, acc=0.399]Evaluation:  32%|###2      | 40/125 [03:07<06:29,  4.58s/it, loss=2.32, acc=0.401]Evaluation:  33%|###2      | 41/125 [03:07<06:26,  4.60s/it, loss=2.32, acc=0.401]Evaluation:  33%|###2      | 41/125 [03:12<06:26,  4.60s/it, loss=2.32, acc=0.403]Evaluation:  34%|###3      | 42/125 [03:12<06:22,  4.61s/it, loss=2.32, acc=0.403]Evaluation:  34%|###3      | 42/125 [03:17<06:22,  4.61s/it, loss=2.32, acc=0.403]Evaluation:  34%|###4      | 43/125 [03:17<06:14,  4.57s/it, loss=2.32, acc=0.403]Evaluation:  34%|###4      | 43/125 [03:21<06:14,  4.57s/it, loss=2.33, acc=0.401]Evaluation:  35%|###5      | 44/125 [03:21<06:09,  4.56s/it, loss=2.33, acc=0.401]Evaluation:  35%|###5      | 44/125 [03:26<06:09,  4.56s/it, loss=2.33, acc=0.4]  Evaluation:  36%|###6      | 45/125 [03:26<06:03,  4.54s/it, loss=2.33, acc=0.4]Evaluation:  36%|###6      | 45/125 [03:30<06:03,  4.54s/it, loss=2.33, acc=0.399]Evaluation:  37%|###6      | 46/125 [03:30<06:01,  4.58s/it, loss=2.33, acc=0.399]Evaluation:  37%|###6      | 46/125 [03:35<06:01,  4.58s/it, loss=2.33, acc=0.401]Evaluation:  38%|###7      | 47/125 [03:35<05:53,  4.54s/it, loss=2.33, acc=0.401]Evaluation:  38%|###7      | 47/125 [03:39<05:53,  4.54s/it, loss=2.34, acc=0.399]Evaluation:  38%|###8      | 48/125 [03:39<05:49,  4.54s/it, loss=2.34, acc=0.399]Evaluation:  38%|###8      | 48/125 [03:44<05:49,  4.54s/it, loss=2.34, acc=0.398]Evaluation:  39%|###9      | 49/125 [03:44<05:42,  4.51s/it, loss=2.34, acc=0.398]Evaluation:  39%|###9      | 49/125 [03:48<05:42,  4.51s/it, loss=2.35, acc=0.398]Evaluation:  40%|####      | 50/125 [03:48<05:38,  4.52s/it, loss=2.35, acc=0.398]Evaluation:  40%|####      | 50/125 [03:53<05:38,  4.52s/it, loss=2.35, acc=0.397]Evaluation:  41%|####      | 51/125 [03:53<05:35,  4.53s/it, loss=2.35, acc=0.397]Evaluation:  41%|####      | 51/125 [03:57<05:35,  4.53s/it, loss=2.35, acc=0.397]Evaluation:  42%|####1     | 52/125 [03:57<05:33,  4.56s/it, loss=2.35, acc=0.397]Evaluation:  42%|####1     | 52/125 [04:02<05:33,  4.56s/it, loss=2.36, acc=0.397]Evaluation:  42%|####2     | 53/125 [04:02<05:25,  4.52s/it, loss=2.36, acc=0.397]Evaluation:  42%|####2     | 53/125 [04:06<05:25,  4.52s/it, loss=2.35, acc=0.398]Evaluation:  43%|####3     | 54/125 [04:06<05:20,  4.52s/it, loss=2.35, acc=0.398]Evaluation:  43%|####3     | 54/125 [04:11<05:20,  4.52s/it, loss=2.35, acc=0.399]Evaluation:  44%|####4     | 55/125 [04:11<05:21,  4.59s/it, loss=2.35, acc=0.399]Evaluation:  44%|####4     | 55/125 [04:16<05:21,  4.59s/it, loss=2.34, acc=0.4]  Evaluation:  45%|####4     | 56/125 [04:16<05:13,  4.54s/it, loss=2.34, acc=0.4]Evaluation:  45%|####4     | 56/125 [04:20<05:13,  4.54s/it, loss=2.34, acc=0.402]Evaluation:  46%|####5     | 57/125 [04:20<05:09,  4.55s/it, loss=2.34, acc=0.402]Evaluation:  46%|####5     | 57/125 [04:25<05:09,  4.55s/it, loss=2.33, acc=0.402]Evaluation:  46%|####6     | 58/125 [04:25<05:04,  4.54s/it, loss=2.33, acc=0.402]Evaluation:  46%|####6     | 58/125 [04:29<05:04,  4.54s/it, loss=2.33, acc=0.401]Evaluation:  47%|####7     | 59/125 [04:29<04:57,  4.51s/it, loss=2.33, acc=0.401]Evaluation:  47%|####7     | 59/125 [04:34<04:57,  4.51s/it, loss=2.33, acc=0.4]  Evaluation:  48%|####8     | 60/125 [04:34<04:53,  4.52s/it, loss=2.33, acc=0.4]Evaluation:  48%|####8     | 60/125 [04:38<04:53,  4.52s/it, loss=2.32, acc=0.4]Evaluation:  49%|####8     | 61/125 [04:38<04:50,  4.54s/it, loss=2.32, acc=0.4]Evaluation:  49%|####8     | 61/125 [04:43<04:50,  4.54s/it, loss=2.32, acc=0.401]Evaluation:  50%|####9     | 62/125 [04:43<04:47,  4.57s/it, loss=2.32, acc=0.401]Evaluation:  50%|####9     | 62/125 [04:47<04:47,  4.57s/it, loss=2.32, acc=0.402]Evaluation:  50%|#####     | 63/125 [04:47<04:42,  4.56s/it, loss=2.32, acc=0.402]Evaluation:  50%|#####     | 63/125 [04:52<04:42,  4.56s/it, loss=2.32, acc=0.402]Evaluation:  51%|#####1    | 64/125 [04:52<04:35,  4.51s/it, loss=2.32, acc=0.402]Evaluation:  51%|#####1    | 64/125 [04:56<04:35,  4.51s/it, loss=2.32, acc=0.401]Evaluation:  52%|#####2    | 65/125 [04:56<04:32,  4.55s/it, loss=2.32, acc=0.401]Evaluation:  52%|#####2    | 65/125 [05:01<04:32,  4.55s/it, loss=2.31, acc=0.402]Evaluation:  53%|#####2    | 66/125 [05:01<04:28,  4.55s/it, loss=2.31, acc=0.402]Evaluation:  53%|#####2    | 66/125 [05:05<04:28,  4.55s/it, loss=2.31, acc=0.403]Evaluation:  54%|#####3    | 67/125 [05:05<04:19,  4.48s/it, loss=2.31, acc=0.403]Evaluation:  54%|#####3    | 67/125 [05:10<04:19,  4.48s/it, loss=2.31, acc=0.402]Evaluation:  54%|#####4    | 68/125 [05:10<04:18,  4.53s/it, loss=2.31, acc=0.402]Evaluation:  54%|#####4    | 68/125 [05:14<04:18,  4.53s/it, loss=2.32, acc=0.402]Evaluation:  55%|#####5    | 69/125 [05:14<04:11,  4.50s/it, loss=2.32, acc=0.402]Evaluation:  55%|#####5    | 69/125 [05:19<04:11,  4.50s/it, loss=2.32, acc=0.402]Evaluation:  56%|#####6    | 70/125 [05:19<04:06,  4.48s/it, loss=2.32, acc=0.402]                                                                                  Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 51, in __getitem__
    (X, label_idx, id) = transform((stretched, label, id), self.transform_params)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py", line 97, in transform
    X = constant_q(
  File "/geode2/home/u080/skarukas/Carbonate/SITH/util.py", line 180, in constant_q
    X = librosa.cqt(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 185, in cqt
    return vqt(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 1010, in vqt
    fft_basis, n_fft, _ = __cqt_filter_fft(
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/core/constantq.py", line 1090, in __cqt_filter_fft
    fft_basis = util.sparsify_rows(fft_basis, quantile=sparsity, dtype=dtype)
  File "/N/u/skarukas/Carbonate/.local/lib/python3.9/site-packages/librosa/util/utils.py", line 1307, in sparsify_rows
    x_sparse[i, idx] = x[i, idx]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/sparse/lil.py", line 333, in __setitem__
    IndexMixin.__setitem__(self, key, x)
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/sparse/_index.py", line 97, in __setitem__
    i, j = _broadcast_arrays(row, col)
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/sparse/_index.py", line 22, in _broadcast_arrays
    x, y = np.broadcast_arrays(a, b)
  File "<__array_function__ internals>", line 5, in broadcast_arrays
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 264, in broadcast_arrays
    return [_broadcast_to(array, shape, subok=subok, readonly=False)
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 264, in <listcomp>
    return [_broadcast_to(array, shape, subok=subok, readonly=False)
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 123, in _broadcast_to
    it = np.nditer(
KeyboardInterrupt
Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]                                                   Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 26, in evaluate
    for (X, label) in dataloader:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/geode2/home/u080/skarukas/Carbonate/SITH/datasets.py", line 48, in __getitem__
    sr = reader.samplerate
AttributeError: 'ArrayReader' object has no attribute 'samplerate'
Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert torch.tensor(X).isfinite().all()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/scipy/stats/stats.py:2555: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  z[np.broadcast_to(isconst, z.shape)] = np.nan
/geode2/home/u080/skarukas/Carbonate/SITH/preprocess_audio.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_norm = torch.tensor(X_norm)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/125 [00:05<?, ?it/s, loss=2.04, acc=0.463]Evaluation:   1%|          | 1/125 [00:05<10:55,  5.29s/it, loss=2.04, acc=0.463]Evaluation:   1%|          | 1/125 [00:09<10:55,  5.29s/it, loss=2.28, acc=0.438]Evaluation:   2%|1         | 2/125 [00:09<09:37,  4.69s/it, loss=2.28, acc=0.438]Evaluation:   2%|1         | 2/125 [00:13<09:37,  4.69s/it, loss=2.21, acc=0.442]Evaluation:   2%|2         | 3/125 [00:13<09:06,  4.48s/it, loss=2.21, acc=0.442]Evaluation:   2%|2         | 3/125 [00:18<09:06,  4.48s/it, loss=2.28, acc=0.425]Evaluation:   3%|3         | 4/125 [00:18<08:51,  4.40s/it, loss=2.28, acc=0.425]Evaluation:   3%|3         | 4/125 [00:22<08:51,  4.40s/it, loss=2.34, acc=0.403]Evaluation:   4%|4         | 5/125 [00:22<08:35,  4.30s/it, loss=2.34, acc=0.403]Evaluation:   4%|4         | 5/125 [00:26<08:35,  4.30s/it, loss=2.34, acc=0.4]  Evaluation:   5%|4         | 6/125 [00:26<08:29,  4.28s/it, loss=2.34, acc=0.4]Evaluation:   5%|4         | 6/125 [00:30<08:29,  4.28s/it, loss=2.32, acc=0.405]Evaluation:   6%|5         | 7/125 [00:30<08:19,  4.23s/it, loss=2.32, acc=0.405]Evaluation:   6%|5         | 7/125 [00:34<08:19,  4.23s/it, loss=2.33, acc=0.405]Evaluation:   6%|6         | 8/125 [00:34<08:12,  4.21s/it, loss=2.33, acc=0.405]Evaluation:   6%|6         | 8/125 [00:38<08:12,  4.21s/it, loss=2.3, acc=0.418] Evaluation:   7%|7         | 9/125 [00:38<08:06,  4.20s/it, loss=2.3, acc=0.418]Evaluation:   7%|7         | 9/125 [00:43<08:06,  4.20s/it, loss=2.27, acc=0.421]Evaluation:   8%|8         | 10/125 [00:43<08:05,  4.23s/it, loss=2.27, acc=0.421]Evaluation:   8%|8         | 10/125 [00:47<08:05,  4.23s/it, loss=2.24, acc=0.428]Evaluation:   9%|8         | 11/125 [00:47<07:58,  4.20s/it, loss=2.24, acc=0.428]                                                                                  Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 162, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 30, in evaluate
    assert not torch.tensor(prediction).isnan().any()
KeyboardInterrupt
Evaluation:   0%|          | 0/138 [00:00<?, ?it/s]/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/138 [00:02<?, ?it/s, loss=0.433, acc=0.85]Evaluation:   1%|          | 1/138 [00:02<06:26,  2.82s/it, loss=0.433, acc=0.85]                                                                                 Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 163, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 29, in evaluate
    prediction = model(X)
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/SITHConClassifier.py", line 46, in forward
    out = self._forward_batch(inp)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/SITHConClassifier.py", line 60, in _forward_batch
    x = self.sithcon_layers[i](x)
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/sithcon_utils/tctct.py", line 80, in forward
    inp = self.tctct(inp)
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/sithcon_utils/tctct.py", line 43, in forward
    x = self.sith(inp)
  File "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/models/sithcon_utils/isith.py", line 87, in forward
    return out[:, :, :, 1:inp.shape[-1]+1]*self.dt*self.k/(self.k+1)
RuntimeError: CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 15.90 GiB total capacity; 12.68 GiB already allocated; 641.75 MiB free; 14.30 GiB reserved in total by PyTorch)
Evaluation:   0%|          | 0/344 [00:00<?, ?it/s]/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(X).isnan().any()
/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  assert not torch.tensor(prediction).isnan().any()
Evaluation:   0%|          | 0/344 [00:01<?, ?it/s, loss=0.321, acc=0.875]Evaluation:   0%|          | 1/344 [00:01<06:27,  1.13s/it, loss=0.321, acc=0.875]Evaluation:   0%|          | 1/344 [00:02<06:27,  1.13s/it, loss=0.535, acc=0.859]Evaluation:   1%|          | 2/344 [00:02<06:24,  1.13s/it, loss=0.535, acc=0.859]Evaluation:   1%|          | 2/344 [00:03<06:24,  1.13s/it, loss=0.566, acc=0.854]Evaluation:   1%|          | 3/344 [00:03<06:23,  1.12s/it, loss=0.566, acc=0.854]Evaluation:   1%|          | 3/344 [00:04<06:23,  1.12s/it, loss=0.483, acc=0.883]Evaluation:   1%|1         | 4/344 [00:04<06:16,  1.11s/it, loss=0.483, acc=0.883]Evaluation:   1%|1         | 4/344 [00:05<06:16,  1.11s/it, loss=0.439, acc=0.894]Evaluation:   1%|1         | 5/344 [00:05<06:21,  1.13s/it, loss=0.439, acc=0.894]Evaluation:   1%|1         | 5/344 [00:06<06:21,  1.13s/it, loss=0.419, acc=0.901]Evaluation:   2%|1         | 6/344 [00:06<06:13,  1.11s/it, loss=0.419, acc=0.901]Evaluation:   2%|1         | 6/344 [00:07<06:13,  1.11s/it, loss=0.375, acc=0.906]Evaluation:   2%|2         | 7/344 [00:07<06:12,  1.10s/it, loss=0.375, acc=0.906]Evaluation:   2%|2         | 7/344 [00:08<06:12,  1.10s/it, loss=0.358, acc=0.906]Evaluation:   2%|2         | 8/344 [00:08<06:12,  1.11s/it, loss=0.358, acc=0.906]Evaluation:   2%|2         | 8/344 [00:09<06:12,  1.11s/it, loss=0.351, acc=0.903]Evaluation:   3%|2         | 9/344 [00:09<06:09,  1.10s/it, loss=0.351, acc=0.903]Evaluation:   3%|2         | 9/344 [00:11<06:09,  1.10s/it, loss=0.358, acc=0.897]Evaluation:   3%|2         | 10/344 [00:11<06:04,  1.09s/it, loss=0.358, acc=0.897]Evaluation:   3%|2         | 10/344 [00:12<06:04,  1.09s/it, loss=0.356, acc=0.892]Evaluation:   3%|3         | 11/344 [00:12<06:00,  1.08s/it, loss=0.356, acc=0.892]Evaluation:   3%|3         | 11/344 [00:13<06:00,  1.08s/it, loss=0.37, acc=0.883] Evaluation:   3%|3         | 12/344 [00:13<05:56,  1.07s/it, loss=0.37, acc=0.883]Evaluation:   3%|3         | 12/344 [00:14<05:56,  1.07s/it, loss=0.363, acc=0.882]Evaluation:   4%|3         | 13/344 [00:14<05:55,  1.08s/it, loss=0.363, acc=0.882]Evaluation:   4%|3         | 13/344 [00:15<05:55,  1.08s/it, loss=0.352, acc=0.886]Evaluation:   4%|4         | 14/344 [00:15<05:50,  1.06s/it, loss=0.352, acc=0.886]Evaluation:   4%|4         | 14/344 [00:16<05:50,  1.06s/it, loss=0.352, acc=0.883]Evaluation:   4%|4         | 15/344 [00:16<05:54,  1.08s/it, loss=0.352, acc=0.883]Evaluation:   4%|4         | 15/344 [00:17<05:54,  1.08s/it, loss=0.356, acc=0.885]Evaluation:   5%|4         | 16/344 [00:17<05:56,  1.09s/it, loss=0.356, acc=0.885]Evaluation:   5%|4         | 16/344 [00:18<05:56,  1.09s/it, loss=0.369, acc=0.882]Evaluation:   5%|4         | 17/344 [00:18<05:57,  1.09s/it, loss=0.369, acc=0.882]Evaluation:   5%|4         | 17/344 [00:19<05:57,  1.09s/it, loss=0.37, acc=0.88]  Evaluation:   5%|5         | 18/344 [00:19<06:01,  1.11s/it, loss=0.37, acc=0.88]Evaluation:   5%|5         | 18/344 [00:20<06:01,  1.11s/it, loss=0.367, acc=0.88]Evaluation:   6%|5         | 19/344 [00:20<06:05,  1.12s/it, loss=0.367, acc=0.88]Evaluation:   6%|5         | 19/344 [00:22<06:05,  1.12s/it, loss=0.376, acc=0.88]Evaluation:   6%|5         | 20/344 [00:22<06:06,  1.13s/it, loss=0.376, acc=0.88]Evaluation:   6%|5         | 20/344 [00:23<06:06,  1.13s/it, loss=0.386, acc=0.878]Evaluation:   6%|6         | 21/344 [00:23<06:04,  1.13s/it, loss=0.386, acc=0.878]Evaluation:   6%|6         | 21/344 [00:24<06:04,  1.13s/it, loss=0.399, acc=0.879]Evaluation:   6%|6         | 22/344 [00:24<05:56,  1.11s/it, loss=0.399, acc=0.879]Evaluation:   6%|6         | 22/344 [00:25<05:56,  1.11s/it, loss=0.407, acc=0.875]Evaluation:   7%|6         | 23/344 [00:25<05:52,  1.10s/it, loss=0.407, acc=0.875]Evaluation:   7%|6         | 23/344 [00:26<05:52,  1.10s/it, loss=0.401, acc=0.876]Evaluation:   7%|6         | 24/344 [00:26<05:50,  1.09s/it, loss=0.401, acc=0.876]Evaluation:   7%|6         | 24/344 [00:27<05:50,  1.09s/it, loss=0.397, acc=0.876]Evaluation:   7%|7         | 25/344 [00:27<05:50,  1.10s/it, loss=0.397, acc=0.876]Evaluation:   7%|7         | 25/344 [00:28<05:50,  1.10s/it, loss=0.41, acc=0.873] Evaluation:   8%|7         | 26/344 [00:28<05:53,  1.11s/it, loss=0.41, acc=0.873]Evaluation:   8%|7         | 26/344 [00:29<05:53,  1.11s/it, loss=0.41, acc=0.874]Evaluation:   8%|7         | 27/344 [00:29<05:56,  1.12s/it, loss=0.41, acc=0.874]Evaluation:   8%|7         | 27/344 [00:30<05:56,  1.12s/it, loss=0.405, acc=0.875]Evaluation:   8%|8         | 28/344 [00:30<05:52,  1.12s/it, loss=0.405, acc=0.875]Evaluation:   8%|8         | 28/344 [00:32<05:52,  1.12s/it, loss=0.414, acc=0.874]Evaluation:   8%|8         | 29/344 [00:32<05:56,  1.13s/it, loss=0.414, acc=0.874]Evaluation:   8%|8         | 29/344 [00:33<05:56,  1.13s/it, loss=0.424, acc=0.871]Evaluation:   9%|8         | 30/344 [00:33<06:01,  1.15s/it, loss=0.424, acc=0.871]Evaluation:   9%|8         | 30/344 [00:34<06:01,  1.15s/it, loss=0.424, acc=0.871]Evaluation:   9%|9         | 31/344 [00:34<06:09,  1.18s/it, loss=0.424, acc=0.871]Evaluation:   9%|9         | 31/344 [00:35<06:09,  1.18s/it, loss=0.423, acc=0.872]Evaluation:   9%|9         | 32/344 [00:35<06:07,  1.18s/it, loss=0.423, acc=0.872]Evaluation:   9%|9         | 32/344 [00:36<06:07,  1.18s/it, loss=0.415, acc=0.875]Evaluation:  10%|9         | 33/344 [00:36<06:10,  1.19s/it, loss=0.415, acc=0.875]Evaluation:  10%|9         | 33/344 [00:38<06:10,  1.19s/it, loss=0.411, acc=0.877]Evaluation:  10%|9         | 34/344 [00:38<06:05,  1.18s/it, loss=0.411, acc=0.877]Evaluation:  10%|9         | 34/344 [00:39<06:05,  1.18s/it, loss=0.423, acc=0.876]Evaluation:  10%|#         | 35/344 [00:39<05:52,  1.14s/it, loss=0.423, acc=0.876]Evaluation:  10%|#         | 35/344 [00:40<05:52,  1.14s/it, loss=0.42, acc=0.875] Evaluation:  10%|#         | 36/344 [00:40<05:59,  1.17s/it, loss=0.42, acc=0.875]Evaluation:  10%|#         | 36/344 [00:41<05:59,  1.17s/it, loss=0.415, acc=0.877]Evaluation:  11%|#         | 37/344 [00:41<05:51,  1.15s/it, loss=0.415, acc=0.877]Evaluation:  11%|#         | 37/344 [00:42<05:51,  1.15s/it, loss=0.427, acc=0.874]Evaluation:  11%|#1        | 38/344 [00:42<06:04,  1.19s/it, loss=0.427, acc=0.874]Evaluation:  11%|#1        | 38/344 [00:44<06:04,  1.19s/it, loss=0.425, acc=0.874]Evaluation:  11%|#1        | 39/344 [00:44<06:15,  1.23s/it, loss=0.425, acc=0.874]Evaluation:  11%|#1        | 39/344 [00:45<06:15,  1.23s/it, loss=0.419, acc=0.875]Evaluation:  12%|#1        | 40/344 [00:45<06:08,  1.21s/it, loss=0.419, acc=0.875]Evaluation:  12%|#1        | 40/344 [00:46<06:08,  1.21s/it, loss=0.417, acc=0.874]Evaluation:  12%|#1        | 41/344 [00:46<06:15,  1.24s/it, loss=0.417, acc=0.874]Evaluation:  12%|#1        | 41/344 [00:47<06:15,  1.24s/it, loss=0.413, acc=0.876]Evaluation:  12%|#2        | 42/344 [00:47<06:08,  1.22s/it, loss=0.413, acc=0.876]Evaluation:  12%|#2        | 42/344 [00:48<06:08,  1.22s/it, loss=0.415, acc=0.875]Evaluation:  12%|#2        | 43/344 [00:48<06:02,  1.20s/it, loss=0.415, acc=0.875]Evaluation:  12%|#2        | 43/344 [00:50<06:02,  1.20s/it, loss=0.411, acc=0.876]Evaluation:  13%|#2        | 44/344 [00:50<06:06,  1.22s/it, loss=0.411, acc=0.876]Evaluation:  13%|#2        | 44/344 [01:00<06:06,  1.22s/it, loss=0.418, acc=0.875]Evaluation:  13%|#3        | 45/344 [01:00<20:06,  4.03s/it, loss=0.418, acc=0.875]Evaluation:  13%|#3        | 45/344 [01:01<20:06,  4.03s/it, loss=0.416, acc=0.876]Evaluation:  13%|#3        | 46/344 [01:01<15:51,  3.19s/it, loss=0.416, acc=0.876]Evaluation:  13%|#3        | 46/344 [01:03<15:51,  3.19s/it, loss=0.423, acc=0.874]Evaluation:  14%|#3        | 47/344 [01:03<13:02,  2.63s/it, loss=0.423, acc=0.874]Evaluation:  14%|#3        | 47/344 [01:04<13:02,  2.63s/it, loss=0.419, acc=0.874]Evaluation:  14%|#3        | 48/344 [01:04<10:59,  2.23s/it, loss=0.419, acc=0.874]Evaluation:  14%|#3        | 48/344 [01:05<10:59,  2.23s/it, loss=0.417, acc=0.876]Evaluation:  14%|#4        | 49/344 [01:05<09:22,  1.91s/it, loss=0.417, acc=0.876]Evaluation:  14%|#4        | 49/344 [01:06<09:22,  1.91s/it, loss=0.418, acc=0.876]Evaluation:  15%|#4        | 50/344 [01:06<08:21,  1.71s/it, loss=0.418, acc=0.876]Evaluation:  15%|#4        | 50/344 [01:08<08:21,  1.71s/it, loss=0.422, acc=0.874]Evaluation:  15%|#4        | 51/344 [01:08<07:41,  1.57s/it, loss=0.422, acc=0.874]Evaluation:  15%|#4        | 51/344 [01:09<07:41,  1.57s/it, loss=0.425, acc=0.873]Evaluation:  15%|#5        | 52/344 [01:09<07:08,  1.47s/it, loss=0.425, acc=0.873]Evaluation:  15%|#5        | 52/344 [01:10<07:08,  1.47s/it, loss=0.423, acc=0.873]Evaluation:  15%|#5        | 53/344 [01:10<06:47,  1.40s/it, loss=0.423, acc=0.873]Evaluation:  15%|#5        | 53/344 [01:16<06:47,  1.40s/it, loss=0.427, acc=0.872]Evaluation:  16%|#5        | 54/344 [01:16<12:26,  2.57s/it, loss=0.427, acc=0.872]Evaluation:  16%|#5        | 54/344 [01:17<12:26,  2.57s/it, loss=0.428, acc=0.872]Evaluation:  16%|#5        | 55/344 [01:17<10:40,  2.22s/it, loss=0.428, acc=0.872]Evaluation:  16%|#5        | 55/344 [01:18<10:40,  2.22s/it, loss=0.429, acc=0.872]Evaluation:  16%|#6        | 56/344 [01:18<09:19,  1.94s/it, loss=0.429, acc=0.872]Evaluation:  16%|#6        | 56/344 [01:19<09:19,  1.94s/it, loss=0.43, acc=0.872] Evaluation:  17%|#6        | 57/344 [01:19<08:16,  1.73s/it, loss=0.43, acc=0.872]Evaluation:  17%|#6        | 57/344 [01:21<08:16,  1.73s/it, loss=0.43, acc=0.871]Evaluation:  17%|#6        | 58/344 [01:21<07:40,  1.61s/it, loss=0.43, acc=0.871]Evaluation:  17%|#6        | 58/344 [01:22<07:40,  1.61s/it, loss=0.427, acc=0.872]Evaluation:  17%|#7        | 59/344 [01:22<07:02,  1.48s/it, loss=0.427, acc=0.872]Evaluation:  17%|#7        | 59/344 [01:23<07:02,  1.48s/it, loss=0.432, acc=0.87] Evaluation:  17%|#7        | 60/344 [01:23<06:39,  1.41s/it, loss=0.432, acc=0.87]Evaluation:  17%|#7        | 60/344 [01:24<06:39,  1.41s/it, loss=0.432, acc=0.87]Evaluation:  18%|#7        | 61/344 [01:24<06:21,  1.35s/it, loss=0.432, acc=0.87]Evaluation:  18%|#7        | 61/344 [01:26<06:21,  1.35s/it, loss=0.435, acc=0.87]Evaluation:  18%|#8        | 62/344 [01:26<06:13,  1.32s/it, loss=0.435, acc=0.87]Evaluation:  18%|#8        | 62/344 [01:27<06:13,  1.32s/it, loss=0.434, acc=0.87]Evaluation:  18%|#8        | 63/344 [01:27<06:11,  1.32s/it, loss=0.434, acc=0.87]Evaluation:  18%|#8        | 63/344 [01:28<06:11,  1.32s/it, loss=0.433, acc=0.87]Evaluation:  19%|#8        | 64/344 [01:28<06:05,  1.30s/it, loss=0.433, acc=0.87]Evaluation:  19%|#8        | 64/344 [01:29<06:05,  1.30s/it, loss=0.432, acc=0.871]Evaluation:  19%|#8        | 65/344 [01:29<05:57,  1.28s/it, loss=0.432, acc=0.871]Evaluation:  19%|#8        | 65/344 [01:31<05:57,  1.28s/it, loss=0.434, acc=0.871]Evaluation:  19%|#9        | 66/344 [01:31<05:52,  1.27s/it, loss=0.434, acc=0.871]Evaluation:  19%|#9        | 66/344 [01:32<05:52,  1.27s/it, loss=0.438, acc=0.869]Evaluation:  19%|#9        | 67/344 [01:32<05:49,  1.26s/it, loss=0.438, acc=0.869]Evaluation:  19%|#9        | 67/344 [01:33<05:49,  1.26s/it, loss=0.437, acc=0.87] Evaluation:  20%|#9        | 68/344 [01:33<05:45,  1.25s/it, loss=0.437, acc=0.87]Evaluation:  20%|#9        | 68/344 [01:34<05:45,  1.25s/it, loss=0.437, acc=0.87]Evaluation:  20%|##        | 69/344 [01:34<05:42,  1.25s/it, loss=0.437, acc=0.87]Evaluation:  20%|##        | 69/344 [01:36<05:42,  1.25s/it, loss=0.443, acc=0.871]Evaluation:  20%|##        | 70/344 [01:36<05:43,  1.25s/it, loss=0.443, acc=0.871]Evaluation:  20%|##        | 70/344 [01:37<05:43,  1.25s/it, loss=0.441, acc=0.87] Evaluation:  21%|##        | 71/344 [01:37<05:42,  1.25s/it, loss=0.441, acc=0.87]Evaluation:  21%|##        | 71/344 [01:38<05:42,  1.25s/it, loss=0.439, acc=0.871]Evaluation:  21%|##        | 72/344 [01:38<05:43,  1.26s/it, loss=0.439, acc=0.871]Evaluation:  21%|##        | 72/344 [01:39<05:43,  1.26s/it, loss=0.441, acc=0.87] Evaluation:  21%|##1       | 73/344 [01:39<05:40,  1.26s/it, loss=0.441, acc=0.87]Evaluation:  21%|##1       | 73/344 [01:41<05:40,  1.26s/it, loss=0.44, acc=0.87] Evaluation:  22%|##1       | 74/344 [01:41<05:40,  1.26s/it, loss=0.44, acc=0.87]                                                                                 Traceback (most recent call last):
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 163, in <module>
    stats = evaluate(model, dataloader, progress_bar=True)
  File "/geode2/home/u080/skarukas/Carbonate/SITH/evaluate.py", line 30, in evaluate
    assert not torch.tensor(prediction).isnan().any()
KeyboardInterrupt
