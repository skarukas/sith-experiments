/geode2/home/u080/skarukas/Carbonate/SITH/models/other_layers/interpolation.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x)
/geode2/home/u080/skarukas/Carbonate/SITH/models/other_layers/interpolation.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  y = torch.tensor(y)
/geode2/home/u080/skarukas/Carbonate/SITH/models/other_layers/ShiftedConv2d.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.shifts = torch.tensor(shifts)
Epoch:   0%|          | 0/40 [00:00<?, ?it/s]
Batch:   0%|          | 0/9158 [00:00<?, ?it/s][A/N/soft/sles15/deeplearning/Python-3.9.7/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "

Batch:   0%|          | 28/9158 [00:10<54:32,  2.79it/s, train_loss=2.3, train_acc=0.25, avg_tr_acc=0.121, avg_tr_loss=7.52][A
Batch:   1%|          | 57/9158 [00:20<53:30,  2.83it/s, train_loss=4.43, train_acc=0.125, avg_tr_acc=0.116, avg_tr_loss=6.08][A
Batch:   1%|          | 86/9158 [00:30<53:04,  2.85it/s, train_loss=7.12, train_acc=0.25, avg_tr_acc=0.122, avg_tr_loss=5.74] [A
Batch:   1%|1         | 115/9158 [00:40<52:46,  2.86it/s, train_loss=4.24, train_acc=0.375, avg_tr_acc=0.128, avg_tr_loss=5.49][A
Batch:   2%|1         | 144/9158 [00:50<52:32,  2.86it/s, train_loss=4.43, train_acc=0.125, avg_tr_acc=0.14, avg_tr_loss=5.14] [A
Batch:   2%|1         | 173/9158 [01:00<52:19,  2.86it/s, train_loss=3.7, train_acc=0, avg_tr_acc=0.143, avg_tr_loss=5.04]    [A