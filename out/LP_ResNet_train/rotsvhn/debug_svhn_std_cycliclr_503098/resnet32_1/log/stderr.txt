/geode2/home/u080/skarukas/Carbonate/SITH/models/other_layers/interpolation.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x)
/geode2/home/u080/skarukas/Carbonate/SITH/models/other_layers/interpolation.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  y = torch.tensor(y)
/geode2/home/u080/skarukas/Carbonate/SITH/models/other_layers/ShiftedConv2d.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.shifts = torch.tensor(shifts)
Epoch:   0%|          | 0/40 [00:00<?, ?it/s]
Batch:   0%|          | 0/9158 [00:00<?, ?it/s][A/N/soft/sles15/deeplearning/Python-3.9.7/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "

Batch:   0%|          | 29/9158 [00:10<53:47,  2.83it/s, train_loss=21.9, train_acc=0.125, avg_tr_acc=0.0819, avg_tr_loss=19.2][A
Batch:   1%|          | 59/9158 [00:20<52:29,  2.89it/s, train_loss=20.8, train_acc=0, avg_tr_acc=0.0826, avg_tr_loss=18]      [A
Batch:   1%|          | 89/9158 [00:30<51:57,  2.91it/s, train_loss=16.7, train_acc=0, avg_tr_acc=0.0758, avg_tr_loss=18.3][A
Batch:   1%|1         | 119/9158 [00:40<51:37,  2.92it/s, train_loss=8.85, train_acc=0.25, avg_tr_acc=0.0882, avg_tr_loss=17.4][A
Batch:   2%|1         | 149/9158 [00:51<51:22,  2.92it/s, train_loss=16.5, train_acc=0, avg_tr_acc=0.0898, avg_tr_loss=17.8]   [A