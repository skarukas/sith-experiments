{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xzJnvNDzSfta"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "!mkdir -p figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tF_h_U6bSftg",
    "outputId": "cdb340ef-3ed4-4644-dd74-23b4eb112cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/soft/rhel7/xalt/2.10.30/libexec/xalt_record_pkg: invalid option -- 'A'\n",
      "/N/soft/rhel7/xalt/2.10.30/libexec/xalt_record_pkg: invalid option -- 'A'\n",
      "/N/soft/rhel7/xalt/2.10.30/libexec/xalt_record_pkg: invalid option -- 'A'\n",
      "/N/soft/rhel7/xalt/2.10.30/libexec/xalt_record_pkg: invalid option -- 'I'\n",
      "/N/soft/rhel7/xalt/2.10.30/libexec/xalt_record_pkg: invalid option -- '/'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.set_context(\"poster\")\n",
    "\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "ttype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "ctype = torch.cuda.LongTensor if torch.cuda.is_available() else torch.LongTensor\n",
    "print(ttype)\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import gridspec\n",
    "from sithcon import TCTCT_Layer as SITHCon_Layer, _TCTCT_Core as _SITHCon_Core, iSITH\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import itertools\n",
    "from csv import DictWriter\n",
    "import os \n",
    "from os.path import join\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from math import factorial\n",
    "import random\n",
    "import matplotlib.patches as patches\n",
    "from itertools import combinations_with_replacement as comb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XACMAjooSfti"
   },
   "outputs": [],
   "source": [
    "# SHORTER\n",
    "MORSE_CODE_DICT = {'1':'.-', '2':'-...', \n",
    "                    '3':'-.-.', '4':'-..', '5':'.', \n",
    "                    '6':'..-.', '7':'--.', '8':'....', \n",
    "                    '9':'..', '0':'.---',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxQ1G9OsSftk",
    "outputId": "00dada9b-7ee6-4c25-9b25-cb74e7e5e02f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 0] 1\n",
      "[1 1 1 0 1 0 1 0 1 0 0 0] 2\n",
      "[1 1 1 0 1 0 1 1 1 0 1 0 0 0] 3\n",
      "[1 1 1 0 1 0 1 0 0 0] 4\n",
      "[1 0 0 0] 5\n",
      "[1 0 1 0 1 1 1 0 1 0 0 0] 6\n",
      "[1 1 1 0 1 1 1 0 1 0 0 0] 7\n",
      "[1 0 1 0 1 0 1 0 0 0] 8\n",
      "[1 0 1 0 0 0] 9\n",
      "[1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0] 0\n"
     ]
    }
   ],
   "source": [
    "morse_code_numpy = {key:np.array([int(x) for x in MORSE_CODE_DICT[key].replace('.', '10').replace('-', '1110')] + [0, 0])\n",
    "                    for key in MORSE_CODE_DICT.keys()}\n",
    "for k in morse_code_numpy.keys():\n",
    "    print(morse_code_numpy[k], k)\n",
    "subset = list(morse_code_numpy.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jLsTMuicPGwR"
   },
   "outputs": [],
   "source": [
    "def gen_item_noisy(samples=10, scale=5, target_scale=.1, display=False):\n",
    "    # We can tests 1s the same length as the items added together or 1 at the end only.\n",
    "    keys = morse_code_numpy.keys()\n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    half = int(samples / 2)\n",
    "    added_indexes = [np.random.randint(half),  \n",
    "                     np.random.randint(half, samples)]\n",
    "    answer = 0\n",
    "    double_prob = 1/4\n",
    "\n",
    "    for s in range(samples):\n",
    "        # Grab Random Morse Code Letter\n",
    "        k = random.sample(keys, 1)[0]\n",
    "        mcl = morse_code_numpy[k]\n",
    "\n",
    "        Mmcl = mcl.repeat(scale)\n",
    "        dim1.append(Mmcl[:, np.newaxis])\n",
    "        if s in added_indexes:\n",
    "            \n",
    "            # dim2.append(np.ones(Mmcl.shape[0])[:, np.newaxis])\n",
    "            temp = np.zeros(Mmcl.shape[0])[:, np.newaxis]\n",
    "            temp[-scale:] = 1.0\n",
    "            if display:\n",
    "                    temp = temp * 2.0\n",
    "            #temp[-1] = 1.0 # TRY THIS AT SOME POINT\n",
    "            dim2.append(temp)\n",
    "            answer += int(k)\n",
    "            if display:\n",
    "                dim1[-1] = dim1[-1]*2.0\n",
    "        else:\n",
    "            dim2.append(np.zeros(Mmcl.shape[0])[:, np.newaxis])\n",
    "    inp = np.concatenate([np.concatenate(dim1, axis=0),\n",
    "                          np.concatenate(dim2, axis=0)], axis=1)\n",
    "    \n",
    "    inp_list = []\n",
    "    for x in inp:\n",
    "        inp_list.append(x)\n",
    "        if random.random() < double_prob:\n",
    "            inp_list.append(x)\n",
    "    \n",
    "    inp = np.stack(inp_list)\n",
    "\n",
    "    target = np.array([answer])\n",
    "    return inp, target*target_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "uTvX5IHJSftk",
    "outputId": "3be9e855-629c-47b8-c7d4-1818bf48ee96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96809/3498076752.py:14: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  k = random.sample(keys, 1)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAFaCAYAAADl6KKiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZqUlEQVR4nO3debQtVX0n8O+PeVIQFXGIEZWY5RCeGJwVnBo1mjjFecCO3UmMRmNLllkxicskJnEZxWi3tlHzknaesCWuKJoW1IgDGhxwHhBBcEB4DIII7P6j6vgOm3Puu8O57z54n89aZ9U9VbXr1Nn7VZ3vq2FXtdYCAMBWu2z0CgAA7GgEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQl2AFX1iKpq4+tDG70+O7uq+rWq+r2qekNVfaGqrhjb5m0LWPZTq+o1VfWpqjqrqi6rqour6vSq+oeqOnQZyzh0XLczq+pnVfX9qnpbVd1lresHDEpHkbDxqur4JI8Y316V5JattbM3bo12blV1WpLDZkx6e2vt8Wtc9mVJ9hzfXpVkS5L9s/U/rD9L8vTW2lvnlH9Qkvcm2WcctSXJ9ZNUkivGsm9ayzoCjiDBhquqGyX5jSSXJHlLhu3yKRu6Uvw8yWlJXp/kd5N8cIHL/t9JnpjkVkn2bK0dmCEw3SfJJ8e//6mqbtsXrKqDk7wrQzj6UJJbtdYOSHJwkjcn2S3JG6rqDgtcX9gpCUiw8Z6QZPck78vw45kkT9u41SHJ3Vtrd26t/bfW2uuSnLuoBbfWntNae2tr7buttSvGcVe01j6e5MFJLs4Qkp4wo/gLMhwt+l6SR7XWvjuW/2GGfzOfTbJHkhcvan1hZyUgwcabhKE3J/lYkjOT/GpV3XVegap60XhNzObx/dPGa1ouqqoLq+oj46mYeeUPq6p/qaozxmtYLqqqb1fVB6rquVW1z9S83xo/6zdmLOdVU9dO3W3G9LeO0140Y9ouVfWUqvpQVf2oqi4fr6V5+6xl9d97LP+sqvp0VV0wjt807zuvRGvtykUsZxWfuyXJN8a3N5ueVlW7JJmc3ntNa+3iruyVSV4+vn1YVV1/PdcVrusEJNhA46mQuyQ5L8mJbbgocHLtybKOIlXV65NsHpdzVZLrJTkqyQeq6tEz5n9oks9kOI33y0naWO6QJEcneUWSW04VOXkc3nfGxx859fdS00+eHllV18tw2upfkjwwyQ2TXJrkpkkem+QTVfWsGcv7xSKSvCfJq5IcPn6H6eUfMxXcbrXEcnYoVXXDJL8yvv1ON/n2SW4y/j3vlN+J43CPJPde7NrBzkVAgo01CUHvaK39fPz7zePw8VW1xzbK/1aSJyX5/STXb63tn+TWST6aYft+VVXt1pV5dYZTev+a5Hattb3GcvtnCDn/mOSyqfk/Og6nw9Dkx/yOSS6aM/3QDIHn8gzX1kybBKPPZQhl+4zrcGCSFya5Mskrq+pec773ozKcjnrm+L1vkCE8fHvO/DusGhw0HqE7Mcm+Ger0n7tZbz8OW5Ivz1pWa+3HSX7YzQ+sgoAEG6Sqdk3y5PHtWybjW2tfTPLFDGHh4dtYzAFJntFae21r7adj+e9kuH7l8gwB5Z5Tn3lQhiNFGct9fepzL2ytfay19t9ba2dMfcbk6M9dqmq/qfH3yXAk581JfpLk3uNpoIlJYPp0a+3SqXV4YIY79r6W5P6ttRNba5eN63B+a+2vk/x5hv3Tn8z53vsl+cPW2mumvvcPW2sXzpl/h1NVL6yqydG7H2QIrIdnOHL0oNbaD7oiNx2H50/qa47vd/MDqyAgwcZ5UIYfse8m+Y9u2uQo0rZOs52ZqXA10Vr7fpJPj2/vODXp4gw/yMkyf0DHwHVWhjuk7jk1aRKAPpLk4xmOQG2aMf1qp9ey9Tv943jNzSyT73+/MUj2zkvyxiXWeXNrrcbXGfPm22AXZwhGP54ad0aG4PepGfPvOw4vnTFt2k/H4X5LzgUsSUCCjXPMOHxru2aHZG/NcCrlIVV14yWWceqMshOTfpRuMBkxHm2ZBJYPjkcxNs0JIdMmZaZPo00HoG1NnzYJWS+sqnNnvTJcI5UMt7PfcMb6nDq5A+zaqrV2XGvt4NbajTOEn4dmOLV2wnhx++4bu4awcxOQYANU1f4Zrh9KZh8BOjPDHW27ZegzZ56Llpg2OQ3T/9A+I8lXkhyU5C+T/GeSC6rq/VX15BnXLCVdABrX/7AkXx1PBfXTD0nySxk6LvxEt6zJkasDMlw3NO81sU+u6Uczxl1rtdZ+2lr7tyT3ynAU6fFJ+ovULxmHe29jcZP6unjJuYAlCUiwMR6XZK/x7y9M3XH1i1e23hW20D6RWmvfTvJrSR6Z5HUZwtJ+GY5g/J8kn+quNUq2Xqh9RFXtneH6o12yNRidluTCJPepqsrWo0efba1dkqub7HceOXUabKnXGTO+xobchr/eWmvTF2f/127y5NqiG1TVXplv0j3AOYtcN9jZCEiwMVYSeu5cVXda5IePHRO+t7X2u62122c4qnNshqNOhyf5i27+r2W4XmaPJPfI1gB00jj9ygzXIR2Y5E6Zf3ot43KSq3clwFaTU6O36cZP7lyrzLlDbeyV/aBufmAVBCTYzsbb3yfX4WzKcI3QvNcJ43zr2rN2a+3c1trLkhw3jjpyxmzTt/vPCkDbmj5xyjh8yKpW9rpvcpdhf4rsK9kaLud1AjoZf3mGwAqskoAE299Tx+HnW2ufb61dMO+V5J3jvE9axoXU21RVu4+nwOaZ3CG154xpk7DzsAxHmb7eWjtnxvSnZPiRnxxV6m0eh0dX1YO3sb43WGr6tc2c67ump98oydPHtx+bntZauyrJ28a3z6yqfbuyuyT5o/HtCdemLg9gRyQgwXY0hpPJg2jfs4wiJ2R4cOrBGTpUXKs7JPnS+DiRX5mEpTE4PTrJ88b5ZvXUPDlCdHiSXXPNo0OnZriQ+Ijx/WmzfqRbax/I8N0ryfFVdez0nXpVdWBVPaKq3petj85YkbX2pF1V+1TVjSavbA2Me0yPn3Gt1vTjUGbdXfiC8TEpD5guW1X7VtWjMlzQfnCGi9tfMqP832a41uuWSd5TVbccy984Q/A8IsPRo7+YURZYAQEJtq+jMjzeI0neva2Zx6NI/298u6jTbLfP8DiRryW5tKrOy3Dt0bsy9GV0apK/mlHuSxn6H5o4qVvX/o61WafXJp6a5L0ZLlR/aZIfVNX5VXXh+BnHZ9udZK6nP85wp9zkNXkG2iO78a9e4XJ3y9COH05y4fgMufMyhJ53Jzl0/PtxrbXP9oVba+cmeUyGvo7+S5LvVtUFGU69PSVDsPqd1trpK1wvoCMgwfY1CTlfX8GP2CRI/WZVHbDGz/9Khh/Y12a8vT/D0+G3ZDgd9uwk95pz5Kfl6qd9ZgWgWdckXUNr7ZLW2iMznK57T4Y7tPbJ0CXBN5O8I8Oppmcv83tdW7wxyXOTvC/D96wM9f+TDPX/Zxke/zL36GJr7UMZrl37pwwdeO6dISC9I8ndW2tvWr/Vh51Hze9jDgBg5+QIEgBAR0ACAOgISAAAnYUFpKo6rqpOqqrjFrVMAID1sK3csrCLtKvqrCQ3z3A3zGkLWSgAwPrYlKFrk7Nba7foJy4yIF0wfhAAwLXFltbaAf3IJbu9X6GLk+xfe+2VPW5+s1+M3Ptbs3u7v/Q217/GuJXMu6hlr9a8ddpZP2upcsuxre+xluWv53ov5zNW4rB79I/fWr3Pn3KNTp4Xtvx+2fOWO2sdVmOl+4DllF2Ltbb3euyj1nMbXE39r6XNlms9f0eWKrMai1yv5Zq1XS61Ta5mO17EPmV7708mLsoFuTJXJNd87mGSxR5BOinJkXve5ta56bOf+Yvxt/2jT86c/5uvuPs1xq1k3kUte7XmrdPO+llLlVuObX2PtSx/Pdd7OZ+xEh/8/mkLWU6SHH2zTeu2/H7Z85Y7ax1WY6X7gOWUXYu1tvd67KPWcxtcTf2vpc2Waz1/R5YqsxqLXK/lmrVdLrVNrmY7XsQ+ZXvvTyZObSflgvw4SU5urR3VT3cXGwBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgIyABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgIyABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgIyABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgIyABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgIyABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgU621xSyo6qQkRx6QG+XX66iFLBPYeXzw+6fNnXb0zTZtt/UArntm7V/u/6izcvIplyXJya21o/rpjiABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgIyABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgIyABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgIyABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgIyABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOgISAAAHQEJAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCgIyABAHQEJACAjoAEANARkAAAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADoCEgBAR0ACAOhUa20xC6o6K8nNd81uuV4OWMgygZ3HYfe4eO60z5+y33ZcE+C6Ztb+5bTTf5YtF7YkObu1dot++iID0gVJ9l/IwgAAto8trbUD+pG7LfADvpPkTkl2TbIlyWkLXDYrsylDWNUOG2tTtMOOYFO0w45iU7TFjmBTtEOS3DbJfhnyyzUsLCC11u5cVSclOTLJaa21oxa1bFZGO+wYtMOOQTvsOLTFjkE7LI+LtAEAOgISAEBHQAIA6AhIAAAdAQkAoCMgAQB0BCQAgI6ABADQEZAAADqLfNRIkmxOclKSMxa8XFZmc7TDjmBztMOOYHO0w45ic7TFjmBztMM2LexhtQAA1xVOsQEAdAQkAICOgAQA0FlIQKqqJ1bVx6pqS1VdXFWnVtUfVJUAtgJVdbuqek5VvamqvlpVV1VVq6rHLKPsqtqgqh5cVSdW1U+q6qdV9aWq+tOq2nNx3+zapap2r6oHVNXfj/V4YVVdXlVnV9W7quqobZTXFgtSVc+uqndU1Veq6ryq+nlV/aiqPlxVT66qmlNul7HOTx3bYMvYJk9Yxmfany1DVb1k3D+1qnr+EvPZHhaoqjZP1fus11fnlLNNrFRrbU2vJP8zSUtyaZJ/TXJ8kgvHce9JsstaP2NneSU5bqy3/vWY9WiDJH88znNFkg8neWeSH47jTkmyz0bXyQa1wwOn6v6csU7fnuSLU+NfrC22S1ucleTyJJ9LckKSt431cdVYN+/t6zTJrkn+7zh9y1jv709y2TjulUt8nv3Z8trliPHf6qQdnr/I+rQ9LFn3m8d6+Pj4d//6mxllbBOrqes1NtSjp35EDp0af5MkXx6nPWejv+S15ZXkGUlemuSxSW6T4TbMJQPSatsgya+PO7dLktxtavx+SU4ey71io+tkg9rh/kneleQ+M6Y9btxptyT30xbr3hb3TrLvjPF3SHLuWDdP76b9j3H86UluMjX+0KkyvzVjmfZny2uTPcf6OHv8sZwZkGwP61b/m8c6OGYFZWwTq6nrNTbUqWMFPXXGtCOnKvY6mzDXtXGWF5BW1QYZAkBL8uczyt06yZVJfpbkgI2uhx3tleT1Y929QVtsaDv82Vhvb5kat2uSH4zj7zujzNPGaZ+eMc3+bHn1/ndjXTx86sd6VkCyPaxP/a8oINkmVv9a9fnDqrpFkrtkOPz9zn56a+3kDP/DODjJ3Vf7Ocy32jaoqj2SPGR8++YZ5b6d4TD2HkkeuvAVv/b7z3F4i8kIbbEhrhiHP5sad48kByU5q7X20Rll3pnk50mOqKqbT0bany1PVd0tw9GIt7TWTlhiPtvDjsM2sUprucDqzuPw9NbapXPm+Uw3L4u12ja4XZJ9kvyktfatFZRjcOg4PGdqnLbYjqrqkCS/N75939SkSR19JjO01n6a4TRDkmyaUc7+bI6q2ivJPyf5SZLnbGN228P6u19VvbyqXldVf1lVR8+5aNo2sUpredTIIePwu0vMc2Y3L4u12jY4pJu23HI7vao6OMkx49t3T03SFuuoqp6e4ZD+7hmO3N0zw3/wXtJaO35q1uW2w6bMbgf7s/n+OkOAeXxr7cfbmNf2sP6eOmPcl6vq8a21L06Ns02s0loC0n7j8JIl5rl4HF5vDZ/DfKttA223ClW1W5I3Jdk/yb93pxi0xfq6V4ZrJSauyHAN0su7+bTDOqiqeyZ5bpL3ttbevowi2mH9nJbksxnu7jszyfWTHJ4hwB6W5MNVdXhr7exxfm2xStftPgxgsV6b5AFJvpfkyRu8LjuV1tozWmuV4fTLHTJ0ifGiJJ+sqptt4Kpd51XV3hkuDL4wyTM3dm1orR3XWntVa+0rrbVLWmvntNben+SuST6Z4XqjP9nYtbxuWEtAmiTHfZeYZ5JAL1rD5zDfattA261QVb0yye9kuCX2Aa21c7tZtMV20Fq7tLX25dbasRl+BA5L8uqpWbTD4r0kw3V3z2utnbOtmUfaYTtrrV2e5G/Gt9MXsGuLVVrLKbYzxuEvLzHPL3XzslhnjMOVtsHk71uusNxOqar+PskfJvlRhnD0jRmznTEOtcX2sznJy5I8vKp2b639PGtvB/uza3pkhn6JnlZVT+um/eo4/P2qeliSb7bWnhHbw0aZ9KJ986lxZ4xD28QKrSUgTW51vkNV7T3nKvcjunlZrNW2wVcz9Ip6YFXdZs7dInedUW6nU1UvTfK8JOcleWBr7ctzZtUW29/5Ga5F2i3JgRn6evncOO2IWQWqap8kdxzfTten/dnSdslwkfw8tx5fB4zvbQ8b44bj8OKpcbaJVVr1KbbW2vcyVPweSX67n15VR2a42+TcDP1WsGCrbYPxUOy/jW+fNKPcrTP0nXF5hu7od0pV9bdJjs3wQ/yg1toX5s2rLTbEfTOEowuSTO6qOiXDkb5bVNV9Z5T57Qx3wn1m6iJW+7MltNZu1VqrWa8Mt/0nybHjuE1jGdvDxnjsOJy+pd82sVpr6WUyyWOytSfN206NPyhDvwrX6W7I1/uV5fWkvao2yJD8J93533Vq/H5Tn/uKja6DDaz7vxrr4Pwkd1lmGW2x2Da4d5KHJdltxrR7JfnWWDcv66Y9P1sfq3DQ1PhDx7Zpmf1YBfuzlbfR5szvSdv2sPj63jRuE7t243fL0IHnlWP9HN1Nt02spr4X0GD/K1sfZHdChofXbRnHHd83pNeSdXl4hrsQJq/JAwG/Pj1+UW2Qqz8Q8sQk78jWLuk/mZ30gZBJfnOsg5bhf2Kb57xeoC3WtR2OydaQ+u8ZelZ+39SOuWV4eObeXbldx/latj6Y84SxTVqSf1jiM+3PVtZGmzMnIK2lPm0Pc+v7EWMdnJfkQ+M28YEMPVq3DAHp2BnlbBOrqe8FNdoTk/xHhh/0SzL00fAHuY4+n2XdGiM5amrHP/e1yDZI8uBxQzt/3ABOT/KnSfbc6PrYwHY4ZjntkOQkbbGu7XBIkhcn+UiG/l4uzfD08TMyPK/rEUuU3SXJs8a6v2Rsi48neeIyPtf+bPlttDlLBKS11KftYWadHJKhi4tPZAhFl411840kb8wSR7ttEyt/1fjlAQAY6SgSAKAjIAEAdAQkAICOgAQA0BGQAAA6AhIAQEdAAgDoCEgAAB0BCQCg8/8B1EsXLZbmnPYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gen_item(samples=10, scale=5, target_scale=.1, display=False):\n",
    "    # We can tests 1s the same length as the items added together or 1 at the end only.\n",
    "    keys = morse_code_numpy.keys()\n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    half = int(samples / 2)\n",
    "    added_indexes = [np.random.randint(half),  \n",
    "                     np.random.randint(half, samples)]\n",
    "    \n",
    "    answer = 0\n",
    "    for s in range(samples):\n",
    "        # Grab Random Morse Code Letter\n",
    "        k = random.sample(keys, 1)[0]\n",
    "        mcl = morse_code_numpy[k]\n",
    "        Mmcl = mcl.repeat(scale)\n",
    "        dim1.append(Mmcl[:, np.newaxis])\n",
    "        if s in added_indexes:\n",
    "            \n",
    "            # dim2.append(np.ones(Mmcl.shape[0])[:, np.newaxis])\n",
    "            temp = np.zeros(Mmcl.shape[0])[:, np.newaxis]\n",
    "            temp[-scale:] = 1.0\n",
    "            if display:\n",
    "                    temp = temp * 2.0\n",
    "            #temp[-1] = 1.0 # TRY THIS AT SOME POINT\n",
    "            dim2.append(temp)\n",
    "            answer += int(k)\n",
    "            if display:\n",
    "                dim1[-1] = dim1[-1]*2.0\n",
    "        else:\n",
    "            dim2.append(np.zeros(Mmcl.shape[0])[:, np.newaxis])\n",
    "    inp = np.concatenate([np.concatenate(dim1, axis=0),\n",
    "                          np.concatenate(dim2, axis=0)], axis=1)\n",
    "    \n",
    "    target = np.array([answer])\n",
    "    return inp, target*target_scale\n",
    "inp, tar = gen_item_noisy(10, 5, .1, display=True)\n",
    "print(inp.shape)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(inp.T,aspect='auto', interpolation='none')\n",
    "plt.title(\"Answer: {:.2f}\".format(tar[0]))\n",
    "plt.yticks([])\n",
    "plt.savefig(join('figs', 'adding_morse_example'), dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "niFiKscdSftm"
   },
   "outputs": [],
   "source": [
    "class SITHCon_Classifier(nn.Module):\n",
    "    def __init__(self, out_classes, layer_params, \n",
    "                 act_func=nn.ReLU, batch_norm=False,\n",
    "                 dropout=.2):\n",
    "        super(SITHCon_Classifier, self).__init__()\n",
    "        last_channels = layer_params[-1]['channels']\n",
    "        self.transform_linears = nn.ModuleList([nn.Linear(l['channels'], l['channels'])\n",
    "                                                for l in layer_params])\n",
    "        self.sithcon_layers = nn.ModuleList([SITHCon_Layer(l, act_func) for l in layer_params])\n",
    "        self.to_out = nn.Linear(last_channels, out_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, inp):\n",
    "        \n",
    "        x = inp\n",
    "        #out = []\n",
    "        for i in range(len(self.sithcon_layers)):\n",
    "            x = self.sithcon_layers[i](x)\n",
    "            \n",
    "            x = F.relu(self.transform_linears[i](x[:,0,:,:].transpose(1,2)))\n",
    "            x = x.unsqueeze(1).transpose(2,3)\n",
    "\n",
    "            #out.append(x.clone())\n",
    "        x = x.transpose(2,3)[:, 0, :, :]\n",
    "        #x = x.transpose(2,3)[:, 0, :, :]\n",
    "        x = self.to_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Bk5inheSfto"
   },
   "source": [
    "# Three Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fxDHlhw-Sftq"
   },
   "outputs": [],
   "source": [
    "params = [[3000, 400, 35, 23, 2, 6000],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nAwmrbHLSftr"
   },
   "outputs": [],
   "source": [
    "def gen_model(p):\n",
    "    sp1 = dict(in_features=2, \n",
    "               tau_min=.1, tau_max=p[0], buff_max=p[5],\n",
    "               dt=1, ntau=p[1], k=p[2], g=0.0, ttype=ttype, \n",
    "               channels=25, kernel_width=p[3], dilation=p[4],\n",
    "               dropout=None, batch_norm=None)\n",
    "    sp2 = dict(in_features=sp1['channels'], \n",
    "               tau_min=.1, tau_max=p[0], buff_max=p[5],\n",
    "               dt=1, ntau=p[1], k=p[2], g=0.0, ttype=ttype, \n",
    "               channels=25, kernel_width=p[3], dilation=p[4], \n",
    "               dropout=None, batch_norm=None)\n",
    "    sp3 = dict(in_features=sp2['channels'], \n",
    "               tau_min=.1, tau_max=p[0], buff_max=p[5],\n",
    "               dt=1, ntau=p[1], k=p[2], g=0.0, ttype=ttype, \n",
    "               channels=25, kernel_width=p[3], dilation=p[4], \n",
    "               dropout=None, batch_norm=None)\n",
    "    layer_params = [sp1, sp2, sp3]\n",
    "    model = SITHCon_Classifier(1, layer_params, act_func=None\n",
    "                              ).cuda()\n",
    "    return model\n",
    "\n",
    "def save_outcome(outcome, filename):\n",
    "    dat = pd.DataFrame(outcome)\n",
    "    dat.to_csv(join('perf',filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-H2iq82uSftu",
    "outputId": "7d4f5aa8-9a10-4399-acf2-ebfcc9c39892",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Weights: 32101\n",
      "SITHCon_Classifier(\n",
      "  (transform_linears): ModuleList(\n",
      "    (0): Linear(in_features=25, out_features=25, bias=True)\n",
      "    (1): Linear(in_features=25, out_features=25, bias=True)\n",
      "    (2): Linear(in_features=25, out_features=25, bias=True)\n",
      "  )\n",
      "  (sithcon_layers): ModuleList(\n",
      "    (0): TCTCT_Layer(\n",
      "      (tctct): _TCTCT_Core(\n",
      "        (sith): iSITH(ntau=400, tau_min=0.1, tau_max=3000, buff_max=6000, dt=1, k=35, g=0.0)\n",
      "        (conv): Conv2d(1, 25, kernel_size=(2, 23), stride=(1, 1), dilation=(1, 2), bias=False)\n",
      "        (maxp): MaxPool1d(kernel_size=356, stride=356, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (1): TCTCT_Layer(\n",
      "      (tctct): _TCTCT_Core(\n",
      "        (sith): iSITH(ntau=400, tau_min=0.1, tau_max=3000, buff_max=6000, dt=1, k=35, g=0.0)\n",
      "        (conv): Conv2d(1, 25, kernel_size=(25, 23), stride=(1, 1), dilation=(1, 2), bias=False)\n",
      "        (maxp): MaxPool1d(kernel_size=356, stride=356, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (2): TCTCT_Layer(\n",
      "      (tctct): _TCTCT_Core(\n",
      "        (sith): iSITH(ntau=400, tau_min=0.1, tau_max=3000, buff_max=6000, dt=1, k=35, g=0.0)\n",
      "        (conv): Conv2d(1, 25, kernel_size=(25, 23), stride=(1, 1), dilation=(1, 2), bias=False)\n",
      "        (maxp): MaxPool1d(kernel_size=356, stride=356, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (to_out): Linear(in_features=25, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = gen_model(params[0])\n",
    "tot_weights = 0\n",
    "for p in model.parameters():\n",
    "    tot_weights += p.numel()\n",
    "print(\"Total Weights:\", tot_weights)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1BtjsJGcSftx"
   },
   "outputs": [],
   "source": [
    "  loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485,
     "referenced_widgets": [
      "6520118455af445da64b134f15670984",
      "a2d394fe1caa41be8bbbcc297e9ac0e1",
      "54162c9ca8a94f65aed6b21bbd22d6a9",
      "e1dbf50f5ebd42a98217f227192b21f0",
      "f4a6e0b822bb40dab554da5f1079e113",
      "a5667f3fa08c490a8ac73f4e3d97aedb",
      "3eb57eef70c74fdcaf347b2362cd5d56",
      "fd57b6ca80554245a08c7776e0b33572",
      "98bd57f840b5405db747c546b8ec4ec2",
      "d7eb037426664ea4970218315258e25f",
      "506f3c2d2fa04eaeb889665055dda2a8"
     ]
    },
    "id": "I_VeFbAASftx",
    "outputId": "2593e73d-e229-4026-9937-86f00687ad20"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b750e852d954d6ea719e05ef4e9171f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|     | 0/40 [00:00<?, ?it/s]     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96809/1754652697.py:13: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  k = random.sample(keys, 1)[0]\n",
      "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/N/soft/rhel7/deeplearning/Python-3.9.6/lib/python3.9/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_96809/541012616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                  tv)\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m#print((torch.round(out[:, -1, :] * 10) / 10), tv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mperf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mperfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0miv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Trainscale = 5\n",
    "epochs = 40\n",
    "trials_per_epoch = 1000\n",
    "batch_size = 32\n",
    "device='cuda'\n",
    "runs = 1\n",
    "history = []\n",
    "for r in range(runs):\n",
    "    model = gen_model(params[0])\n",
    "    model.load_state_dict(torch.load(join('','SITHCon_morseadding_run_{}.pt'.format(r))))\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "    progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
    "\n",
    "    for epoch_idx in progress_bar:\n",
    "        perfs = []\n",
    "        losses = []\n",
    "        model.train()\n",
    "        for batch_idx in range(trials_per_epoch):\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "            for i in range(batch_size):\n",
    "                iv, tar = gen_item(10,Trainscale, .1)\n",
    "                iv = ttype(iv).unsqueeze(0).unsqueeze(0).transpose(-1,-2)\n",
    "                tv = ttype(tar)\n",
    "                out = model(iv)\n",
    "                loss += loss_func(out[:, -1, :],\n",
    "                                 tv)\n",
    "                #print((torch.round(out[:, -1, :] * 10) / 10), tv)\n",
    "                perf = (torch.round(out[:, -1, :] * 10) / 10).item() == round(tv.item())\n",
    "                perfs.append(perf)\n",
    "                del iv, tar, out\n",
    "            loss = loss / batch_size\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "            #perfs = perfs[int(-loss_buffer_size/batch_size):]\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "            #losses = losses[int(-loss_buffer_size/batch_size):]\n",
    "            \n",
    "            perf_avg = np.sum(perfs)/((len(perfs)))\n",
    "            s = \"{}:{:2} Loss: {:.4f}, Perf: {:.4f}\"\n",
    "            format_list = [epoch_idx, batch_idx, np.mean(losses), perf_avg.item()]\n",
    "            s = s.format(*format_list)\n",
    "            progress_bar.set_description(s)\n",
    "            if batch_idx % 100 == 0:\n",
    "                f = open(f\"history_{r}.p\", \"wb\")\n",
    "                pickle.dump(history, f)\n",
    "                torch.save(model.state_dict(), 'SITHCon_morseadding_run_{}.pt'.format(r))\n",
    "        history.append(sum(losses) / trials_per_epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYCtlLc1Sfty"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGuGmQh6Sfty"
   },
   "outputs": [],
   "source": [
    "items = np.load('generated_adding_morse.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "PNv424W3Sftz",
    "outputId": "af18a808-2238-446e-c180-f031cd4b8161",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96809/1754652697.py:13: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  k = random.sample(keys, 1)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.16549301\n",
      "3 0.10222519\n",
      "4 0.102583416\n",
      "5 0.14806679\n",
      "6 0.1617673\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_96809/593811795.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 loss = loss_func(out[:, -1, :],\n\u001b[1;32m     26\u001b[0m                                      tv)\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mevaldDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_perf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runs = 5\n",
    "device='cuda'\n",
    "num_items = 300\n",
    "for r in [0]:\n",
    "    model.load_state_dict(torch.load('SITHCon_morseadding_run_{}.pt'.format(r)))\n",
    "    model.eval()\n",
    "    evald = []\n",
    "    evaldDict = {'test_perf':[],\n",
    "                 'rate':[]}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for nr in [1,3,4,5,6,12,25,50]:\n",
    "        #for nr in range(1,40,):\n",
    "            losses = []\n",
    "            perfs = []\n",
    "            for i in range(num_items):\n",
    "                iv, tar = gen_item(10,nr, .1)\n",
    "\n",
    "                iv = ttype(iv).unsqueeze(0).unsqueeze(0).transpose(-1,-2).unsqueeze(-1)\n",
    "                iv = iv.repeat(1,1,1,1,nr)\n",
    "                iv = iv.reshape(1,1,2,-1)\n",
    "                tv = torch.FloatTensor(tar).to(device)\n",
    "                out = model(iv)\n",
    "\n",
    "                loss = loss_func(out[:, -1, :],\n",
    "                                     tv)\n",
    "                losses.append(loss.detach().cpu().numpy())\n",
    "            print(nr, np.mean(losses))\n",
    "            evaldDict['test_perf'].append(np.mean(losses))\n",
    "            evaldDict['rate'].append(nr)\n",
    "            evald.append([nr, np.mean(losses)])\n",
    "        scale_perfs = pd.DataFrame(evaldDict)\n",
    "        scale_perfs.to_pickle(join(\"perf\", \"sithcon_morseadding_test_{}.dill\".format(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xsdAfg3Sftz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [[3000, 400, 35, 23, 2, 6000],]\n",
    "model = gen_model(params[0])\n",
    "tot_weights = 0\n",
    "for p in model.parameters():\n",
    "    tot_weights += p.numel()\n",
    "print(\"Total Weights:\", tot_weights)\n",
    "print(model)\n",
    "c = model.sithcon_layers[0].sithcon.sith.c\n",
    "print(c)\n",
    "ntau = 300\n",
    "m = .1\n",
    "maxt = m*(c+1)**(ntau-1)\n",
    "params.append([maxt, ntau, 35, 23, 2, maxt*3])\n",
    "ntau = 350\n",
    "maxt = m*(c+1)**(ntau-1)\n",
    "params.append([maxt, ntau, 35, 23, 2, maxt*3])\n",
    "ntau = 450\n",
    "maxt = m*(c+1)**(ntau-1)\n",
    "params.append([maxt, ntau, 35, 23, 2, maxt*3])\n",
    "ntau = 500\n",
    "maxt = m*(c+1)**(ntau-1)\n",
    "params.append([maxt, ntau, 35, 23, 2, maxt*3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Za4_dr6TSft0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perfs = []\n",
    "for p in params[-1:]:\n",
    "    \n",
    "    model = gen_model(p)\n",
    "    model.load_state_dict(torch.load(join('perf','SITHCon_morseadding_run_{}.pt'.format(0))))\n",
    "    model.eval()\n",
    "    evald = []\n",
    "    evaldDict = {'test_perf':[],\n",
    "                 'rate':[]}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for nr in [150]:\n",
    "        #for nr in range(1,40,):\n",
    "            losses = []\n",
    "            perfs = []\n",
    "            for iv, tar in items:\n",
    "                iv = ttype(iv).unsqueeze(0).unsqueeze(0).transpose(-1,-2).unsqueeze(-1)\n",
    "                iv = iv.repeat(1,1,1,1,nr)\n",
    "                iv = iv.reshape(1,1,2,-1)\n",
    "                tv = torch.FloatTensor(tar).to(device)\n",
    "                out = model(iv)\n",
    "\n",
    "                loss = loss_func(out[:, -1, :],\n",
    "                                     tv)\n",
    "                losses.append(loss.detach().cpu().numpy())\n",
    "            print(nr, np.mean(losses))\n",
    "            evaldDict['test_perf'].append(np.mean(losses))\n",
    "            evaldDict['rate'].append(nr)\n",
    "            evald.append([nr, np.mean(losses)])\n",
    "    scale_perfs = pd.DataFrame(evaldDict)\n",
    "    perfs.append(scale_perfs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HV1PRKu6Sft0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SITHCon-MorseAddingProblem.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "47.7167px",
    "left": "1045.97px",
    "top": "52px",
    "width": "161.033px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3eb57eef70c74fdcaf347b2362cd5d56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "506f3c2d2fa04eaeb889665055dda2a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54162c9ca8a94f65aed6b21bbd22d6a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3eb57eef70c74fdcaf347b2362cd5d56",
      "placeholder": "​",
      "style": "IPY_MODEL_a5667f3fa08c490a8ac73f4e3d97aedb",
      "value": ""
     }
    },
    "6520118455af445da64b134f15670984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54162c9ca8a94f65aed6b21bbd22d6a9",
       "IPY_MODEL_e1dbf50f5ebd42a98217f227192b21f0",
       "IPY_MODEL_f4a6e0b822bb40dab554da5f1079e113"
      ],
      "layout": "IPY_MODEL_a2d394fe1caa41be8bbbcc297e9ac0e1"
     }
    },
    "98bd57f840b5405db747c546b8ec4ec2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2d394fe1caa41be8bbbcc297e9ac0e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5667f3fa08c490a8ac73f4e3d97aedb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7eb037426664ea4970218315258e25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1dbf50f5ebd42a98217f227192b21f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98bd57f840b5405db747c546b8ec4ec2",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd57b6ca80554245a08c7776e0b33572",
      "value": 33
     }
    },
    "f4a6e0b822bb40dab554da5f1079e113": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_506f3c2d2fa04eaeb889665055dda2a8",
      "placeholder": "​",
      "style": "IPY_MODEL_d7eb037426664ea4970218315258e25f",
      "value": "33:71 Loss: 0.0107, Perf: 0.0972:  82%|████▏| 33/40 [1:33:58&lt;19:29, 167.00s/it]     "
     }
    },
    "fd57b6ca80554245a08c7776e0b33572": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
